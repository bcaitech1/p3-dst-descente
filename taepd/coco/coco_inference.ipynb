{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827087d2-3ff0-4099-8f57-cfa6d8788934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BartForConditionalGeneration\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from data_utils import split_slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3b08ae-494c-4d52-b798-1beaeb97d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open( \"../input/data/train_dataset/train_dials.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e403284e-83ea-4184-aaf8-0369361decd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"hyunwoongko/kobart\")\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"hyunwoongko/kobart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201aea3-fd69-4589-aa65-6f6bce859957",
   "metadata": {},
   "source": [
    "## InputExample 및 Feature 정의, 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f37c5e7-d0ba-4393-826b-5c6f3d50b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CoCoGenInputExample:\n",
    "    guid: str\n",
    "    system_utter: str\n",
    "    turn_state: List[str]\n",
    "    user_utter: str\n",
    "\n",
    "@dataclass\n",
    "class CoCoGenInputFeature:\n",
    "    input_id: List[int]\n",
    "    target_id: List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a859f0e3-5955-4d40-937e-9b5f8c090e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coco_examples_from_dialogue(dialogue):\n",
    "    \"\"\" Dialogue 데이터셋 파일 -> CoCoGenInputExamples \"\"\"\n",
    "    guid = dialogue[\"dialogue_idx\"]\n",
    "    examples = []\n",
    "    d_idx = 0\n",
    "    previous_state = []\n",
    "    for idx, turn in enumerate(dialogue[\"dialogue\"]):\n",
    "        if turn[\"role\"] != \"user\":\n",
    "            continue\n",
    "\n",
    "        if idx:\n",
    "            sys_utter = dialogue[\"dialogue\"][idx - 1][\"text\"]\n",
    "        else:\n",
    "            sys_utter = \"\"\n",
    "\n",
    "        user_utter = turn[\"text\"]\n",
    "        state = turn.get(\"state\")\n",
    "\n",
    "        turn_state = sorted(list(set(state) - set(previous_state)))\n",
    "        examples.append(CoCoGenInputExample(guid=f\"{guid}-{d_idx}\",\n",
    "                                            system_utter=sys_utter,\n",
    "                                            turn_state=turn_state,\n",
    "                                            user_utter=user_utter))\n",
    "\n",
    "        d_idx += 1\n",
    "        previous_state = state\n",
    "\n",
    "    return examples\n",
    "\n",
    "\n",
    "def convert_example_to_feature(example, tokenizer):\n",
    "    \"\"\" CoCoGenInputExamples -> CoCoGenInputFeature \"\"\"\n",
    "    sys = tokenizer.tokenize(example.system_utter)\n",
    "    turn_state = ', '.join([s.replace('-', ' ') for s in example.turn_state])\n",
    "    state = tokenizer.tokenize(turn_state)\n",
    "    user = [tokenizer.bos_token] + tokenizer.tokenize(example.user_utter) + [tokenizer.eos_token]\n",
    "\n",
    "    input_tokens = [tokenizer.bos_token] + sys + [tokenizer.eos_token] + state + [tokenizer.eos_token]\n",
    "    input_id = tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "    target_id = tokenizer.convert_tokens_to_ids(user)\n",
    "\n",
    "    return CoCoGenInputFeature(input_id=input_id, target_id=target_id)\n",
    "\n",
    "\n",
    "def pad_ids(arrays, pad_idx, max_length=-1):\n",
    "    if max_length < 0:\n",
    "        max_length = max(list(map(len, arrays)))\n",
    "\n",
    "    arrays = [array + [pad_idx] * (max_length - len(array)) for array in arrays]\n",
    "    return arrays\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.LongTensor(pad_ids([b.input_id for b in batch], tokenizer.pad_token_id))\n",
    "    target_ids = torch.LongTensor(pad_ids([b.target_id for b in batch], -100))\n",
    "    input_masks = input_ids.ne(tokenizer.pad_token_id).float()\n",
    "    return input_ids, target_ids, input_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44535e59-8619-4165-abec-7508b0c4e87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:00<00:00, 18069.44it/s]\n",
      "100%|██████████| 51245/51245 [00:20<00:00, 2539.17it/s]\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "for dialogue in tqdm(data):\n",
    "    examples.extend(get_coco_examples_from_dialogue(dialogue))\n",
    "\n",
    "features = []\n",
    "for example in tqdm(examples):\n",
    "    features.append(convert_example_to_feature(example, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6d480-acec-4f14-b304-01c89815145a",
   "metadata": {},
   "source": [
    "## Data Loader 및 Optimization 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c2192f-a24a-4357-804d-9ed87198ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 50\n",
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "warmup_ratio = 0.1\n",
    "weight_decay = 0.01\n",
    "\n",
    "n_gpu = torch.cuda.device_count()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4e7411-1a84-41c5-97f3-d66afff26208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoCoGenDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        self.length = len(self.features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "train_data = CoCoGenDataset(features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5a955f-8e93-43f8-9fe0-66197871a740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t_total = len(train_loader) * num_train_epochs\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(t_total * warmup_ratio), num_training_steps=t_total\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab08296-bbdc-4314-89fb-d399c234c651",
   "metadata": {},
   "source": [
    "## 50epoch 학습된 모델 체크포인트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50fff427-4fc2-4b59-a03d-5abc95dd8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./coco/training_best_checkpoint.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59af22da-7764-431c-8449-3819f7bcb901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler.state_dict', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b59121e-9315-4cef-afbf-54b9c1b70281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:234: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler.state_dict'])\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e6205b4-c7c4-4882-92f1-9ba902fbbe2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
       "      (layers): ModuleList(\n",
       "        (0): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
       "      (layers): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca1a681-6da4-4b3d-84a4-00d9a5ea7013",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e3264be-00ed-45e1-b5aa-82d4c63e32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_generator(example, slot_value_dict, slot_comb_dict={}, verbose=False):\n",
    "    if not example.turn_state:\n",
    "        return example\n",
    "\n",
    "    coco = deepcopy(example)\n",
    "    num_state = len(coco.turn_state)\n",
    "    is_drop = False\n",
    "\n",
    "    # drop: dialogue state 중 하나를 제거합니다. (e.g., [식당-종류-양식당, 식당-예약 시간-18:00] -> [식당-종류-양식당])\n",
    "    if num_state > 1:\n",
    "        drop_idx = random.choice(range(num_state))\n",
    "        coco.turn_state.pop(drop_idx)\n",
    "        num_state -= 1\n",
    "        is_drop = True\n",
    "\n",
    "    # change: dialogue state의 value 중 하나를 다른 value로 대체합니다. (e.g., [식당-종류-양식당] -> [식당-종류-중식당])\n",
    "    change_idx = random.choice(range(num_state))\n",
    "    origin_slot_value = coco.turn_state[change_idx]\n",
    "    st, sv = split_slot(origin_slot_value, True)\n",
    "    candidates = slot_value_dict.get(st, [sv])\n",
    "    new_sv = random.choice(candidates[1:])\n",
    "    new_slot_value = f\"{st}-{new_sv}\"\n",
    "    coco.turn_state[change_idx] = new_slot_value\n",
    "\n",
    "    # add: slot_comb_dict에서 하나의 slot-value를 생성합니다. (e.g., [식당-종류-중식당] -> [식당-종류-중식당, 식당-예약 인원-2])\n",
    "    combinations = slot_comb_dict.get(st)\n",
    "\n",
    "    if not combinations:\n",
    "        return coco\n",
    "\n",
    "    co_st = random.choice(combinations)\n",
    "    candidates = slot_value_dict.get(co_st, ['dontcare'])\n",
    "    co_sv = random.choice(candidates[1:])\n",
    "    new_slot_value = f\"{co_st}-{co_sv}\"\n",
    "    coco.turn_state.append(new_slot_value)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Before:\", example.turn_state)\n",
    "        print(\"After:\", coco.turn_state)\n",
    "\n",
    "    return coco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c5618-46fc-4d83-bbcf-8ce11cf19403",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd6c072-98e3-4f59-9f25-f87d699cc53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_value_dict = json.load(open('../input/data/train_dataset/ontology.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241ede82-20d6-4ca9-8ae5-dd30d653a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_comb_dict = {\n",
    "    '숙소-가격대': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-종류': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-지역': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-인터넷 가능': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-주차 가능': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-흡연 가능': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-조식 가능': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-헬스장 유무': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-수영장 유무': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간'],\n",
    "    '숙소-스파 유무': ['숙소-예약 명수', '숙소-예약 요일', '숙소-예약 기간']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4131dc47-4923-410b-b2d6-a014147f6ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoCoGenInputExample(guid='morning-silence-2458:관광_식당_지하철_11-0', system_utter='', turn_state=['관광-종류-공원', '관광-지역-서울 중앙'], user_utter='안녕하세요. 서울 중앙에 있는 공원을 방문하고 싶은데요. 추천 좀 해주세요.')\n"
     ]
    }
   ],
   "source": [
    "x = random.choice(examples)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84dec1a2-6511-430b-9f7f-f48a7556b92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoCoGenInputExample(guid='morning-silence-2458:관광_식당_지하철_11-0', system_utter='', turn_state=['관광-지역-서울 서쪽'], user_utter='안녕하세요. 서울 중앙에 있는 공원을 방문하고 싶은데요. 추천 좀 해주세요.')\n"
     ]
    }
   ],
   "source": [
    "x = coco_generator(x, slot_value_dict, slot_comb_dict, verbose=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76ba86a0-63d5-4b66-b151-a19e7bb8b667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoCoGenInputFeature(input_id=[0, 1, 15310, 14331, 14245, 28155, 1], target_id=[0, 27616, 25161, 14245, 14957, 11786, 14082, 14061, 14810, 14941, 14058, 16441, 9828, 14543, 16764, 14813, 19024, 25161, 1])\n"
     ]
    }
   ],
   "source": [
    "x = convert_example_to_feature(x, tokenizer)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ae6ae56-e609-4128-b36d-6812ed180b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: <s></s> 관광 지역 서울 서쪽</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"input:\", tokenizer.decode(x.input_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bc78589-3b3f-48b9-9816-156b8635aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Huggingface의 BartForConditionalGeneration은 model.generate를 통해 쉽게 generation을 진행할 수 있습니다 🙌🏻\n",
    "input_id = torch.LongTensor([x.input_id]).to(device)\n",
    "o = model.generate(input_id,\n",
    "                   decoder_start_token_id=tokenizer.bos_token_id,\n",
    "                   bos_token_id=tokenizer.bos_token_id,\n",
    "                   eos_token_id=tokenizer.eos_token_id,\n",
    "                   pad_token_id=tokenizer.pad_token_id,\n",
    "                   max_length=30,\n",
    "                   early_stopping=True,\n",
    "                   num_beams=8,\n",
    "                   top_k=30,\n",
    "                   temperature=1.5,\n",
    "                   do_sample=True)\n",
    "q = tokenizer.decode(o.tolist()[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dc54f11-9903-4670-8939-d502b47021a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 안녕하세요. 서울 중앙에 있는 공원을 방문하고 싶은데요. 추천 좀 해주세요.\n",
      "After: 안녕하세요. 서울 서쪽에 유명한 관광지가 있나요?\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\", tokenizer.decode(x.target_id, skip_special_tokens=True))\n",
    "print(\"After:\", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd91a47-ec03-420b-af79-47b30569abb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
