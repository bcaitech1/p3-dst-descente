{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sumbt_baseline(for wandb sweep)\n",
    "- checkpoint\n",
    "    - add checkpoint\n",
    "    - add checkpoint saving process\n",
    "    - update checkpoint type(available countinous training)\n",
    "- update validation per epoch or minimal loss\n",
    "- add wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Koaz3guQ6B7k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from data_utils import get_examples_from_dialogues, convert_state_dict, load_dataset\n",
    "from data_utils import OntologyDSTFeature, DSTPreprocessor, _truncate_seq_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# !wandb login  # run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_output_dir(output_path, exist_ok=False):\n",
    "  path = Path(output_path)\n",
    "  if (path.exists() and exist_ok) or (not path.exists()):\n",
    "    return str(path)\n",
    "  else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" %path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### argparse setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'batch_size': 8,  # 8\n",
    "    'hidden_dim': 300,\n",
    "    'num_rnn_layers': 1,\n",
    "    'zero_init_rnn': False,\n",
    "    'max_seq_length': 64,\n",
    "    'max_label_length': 12,\n",
    "    'attn_head': 4,  # 4\n",
    "    'fix_utterance_encoder': False,\n",
    "    'task_name': 'sumbtgru',\n",
    "    'distance_metric': 'euclidean',\n",
    "    'model_name_or_path': 'dsksd/bert-ko-small-minimal',\n",
    "    'warmup_ratio': 0.1,\n",
    "    'learning_rate': 5e-5,  # 5e-5\n",
    "    'weight_decay': 0.01,  # 0.01\n",
    "    'num_train_epochs': 10\n",
    "}\n",
    "\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb sweep 생성 시 parameters에 전달하는 config 설정\n",
    "hyperparameter_defaults = dict(\n",
    "    batch_size = args.batch_size,\n",
    "    learning_rate = args.learning_rate,\n",
    "    epochs = args.num_train_epochs,\n",
    "    weight_decay = args.weight_decay,\n",
    "    attn_head = args.attn_head,\n",
    "    distance_metric = args.distance_metric,\n",
    "    \n",
    "#     dropout = 0.1,\n",
    "#     smoothing = 0.2\n",
    "#     model_name = 'BertForSequenceClassification',\n",
    "#     tokenizer_name = 'BertTokenizer',\n",
    "    )\n",
    "\n",
    "# wandb.init(config=hyperparameter_defaults, project=\"SUMBT-sweep\")\n",
    "# config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wandb sweep config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 4yym5838\n",
      "Sweep URL: https://wandb.ai/taepd/SUMBT-sweep/sweeps/4yym5838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4yym5838'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"SUMBT-sweep\",\n",
    "  \"method\": \"bayes\",\n",
    "  \"metric\": {\n",
    "      \"goal\": \"maximize\",\n",
    "      \"name\": \"Joint Goal Accuracy\"},\n",
    "  \"parameters\": {\n",
    "      \"attn_head\": {\n",
    "          \"distribution\": \"int_uniform\",\n",
    "          \"max\": 12,\n",
    "          \"min\": 4\n",
    "      },\n",
    "      \"batch_size\": {\n",
    "          \"distribution\": \"int_uniform\",\n",
    "          \"max\": 12,\n",
    "          \"min\": 8\n",
    "      },\n",
    "      \"distance_metric\": {\n",
    "          \"distribution\": \"categorical\",\n",
    "          \"values\": [\"euclidean\", \"cosine\"]\n",
    "      },\n",
    "      \"learning_rate\": {\n",
    "          \"distribution\": \"uniform\",\n",
    "          \"max\": 1e-03,\n",
    "          \"min\": 5e-05\n",
    "      },\n",
    "      \"weight_decay\": {\n",
    "          \"distribution\": \"uniform\",\n",
    "          \"max\": 0.02,\n",
    "          \"min\": 0.005\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"SUMBT-sweep\")\n",
    "sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU        \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCYa_jbt6B7m"
   },
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "y2Jpgv4i6B7n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_file = \"/opt/ml/repo/taepd/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Vu232Prn6B7n",
    "outputId": "a17014f7-81fd-41c6-c4e6-c4958942a45e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 8456.91it/s] \n",
      "100%|██████████| 699/699 [00:00<00:00, 11855.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_examples = get_examples_from_dialogues(data=train_data,\n",
    "                                             user_first=True,\n",
    "                                             dialogue_level=True)\n",
    "\n",
    "dev_examples = get_examples_from_dialogues(data=dev_data,\n",
    "                                           user_first=True,\n",
    "                                           dialogue_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aGKZk4_n6B7o",
    "outputId": "5502faa6-a80f-496a-fe8f-399ecd62350f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6301"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1qqe5Hw36B7o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_turn = max([len(e['dialogue']) for e in train_data])\n",
    "tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(max_turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq2fddAg6B7p"
   },
   "source": [
    "## TODO-1: SUMBT Preprocessor 정의 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCoRCk1z6B7p"
   },
   "source": [
    "Ontology-based DST model인 SUMBT의 InputFeature를 만들기 위한 Preprocessor를 정의해야 합니다. <br>\n",
    "\n",
    "1. `_convert_examples_to_features` 함수의 빈칸을 매워 완성하세요.\n",
    "2. `recover_state` 함수의 빈칸을 매워 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p8MjYjqw6B7p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SUMBTPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=64,\n",
    "        max_turn_length=12,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_turn_length = max_turn_length\n",
    "\n",
    "    def _convert_example_to_feature(self, example):\n",
    "        guid = example[0].guid.rsplit(\"-\", 1)[0]  # dialogue_idx\n",
    "        turns = []\n",
    "        token_types = []\n",
    "        labels = []\n",
    "        num_turn = None\n",
    "        for turn in example[: self.max_turn_length]:\n",
    "            assert len(turn.current_turn) == 2\n",
    "            uttrs = []\n",
    "            for segment_idx, uttr in enumerate(turn.current_turn):\n",
    "                token = self.src_tokenizer.encode(uttr, add_special_tokens=False)\n",
    "                uttrs.append(token)\n",
    "\n",
    "            _truncate_seq_pair(uttrs[0], uttrs[1], self.max_seq_length - 3)\n",
    "            tokens = (\n",
    "                [self.src_tokenizer.cls_token_id]\n",
    "                + uttrs[0]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "                + uttrs[1]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "            )\n",
    "            token_type = [0] * (len(uttrs[0]) + 2) + [1] * (len(uttrs[1]) + 1)\n",
    "            if len(tokens) < self.max_seq_length:\n",
    "                gap = self.max_seq_length - len(tokens)\n",
    "                tokens.extend([self.src_tokenizer.pad_token_id] * gap)\n",
    "                token_type.extend([0] * gap)\n",
    "            turns.append(tokens)\n",
    "            token_types.append(token_type)\n",
    "            label = []\n",
    "            if turn.label:\n",
    "                slot_dict = convert_state_dict(turn.label)\n",
    "            else:\n",
    "                slot_dict = {}\n",
    "            for slot_type in self.slot_meta:\n",
    "                value = slot_dict.get(slot_type, \"none\")\n",
    "                # TODO\n",
    "                # raise Exception('label_idx를 ontology에서 꺼내오는 코드를 작성하세요!')\n",
    "#                 label_idx = self.ontology[slot_type].index(value)  # 이렇게 해도 될듯한데?\n",
    "                if value in self.ontology[slot_type]:\n",
    "                    label_idx = self.ontology[slot_type].index(value)\n",
    "                else:\n",
    "                    label_idx = self.ontology[slot_type].index(\"none\")\n",
    "                label.append(label_idx)\n",
    "            labels.append(label)\n",
    "        num_turn = len(turns)\n",
    "        if len(turns) < self.max_turn_length:\n",
    "            gap = self.max_turn_length - len(turns)\n",
    "            for _ in range(gap):\n",
    "                dummy_turn = [self.src_tokenizer.pad_token_id] * self.max_seq_length\n",
    "                turns.append(dummy_turn)\n",
    "                token_types.append(dummy_turn)\n",
    "                dummy_label = [-1] * len(self.slot_meta)\n",
    "                labels.append(dummy_label)\n",
    "        return OntologyDSTFeature(\n",
    "            guid=guid,\n",
    "            input_ids=turns,\n",
    "            segment_ids=token_types,\n",
    "            num_turn=num_turn,\n",
    "            target_ids=labels,\n",
    "        )\n",
    "\n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "    def recover_state(self, pred_slots, num_turn):\n",
    "        states = []\n",
    "        for pred_slot in pred_slots[:num_turn]:\n",
    "            state = []\n",
    "            for s, p in zip(self.slot_meta, pred_slot):\n",
    "                v = self.ontology[s][p]\n",
    "                if v != \"none\":\n",
    "                    state.append(f\"{s}-{v}\")\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor([b.input_ids for b in batch])\n",
    "        segment_ids = torch.LongTensor([b.segment_ids for b in batch])\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "        target_ids = torch.LongTensor([b.target_ids for b in batch])\n",
    "        num_turns = [b.num_turn for b in batch]\n",
    "        return input_ids, segment_ids, input_masks, target_ids, num_turns, guids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhFMIiFy6B7q"
   },
   "source": [
    "## Convert_Examples_to_Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EKluwCmH6B7r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = SUMBTPreprocessor(slot_meta,\n",
    "                              tokenizer,\n",
    "                              ontology=ontology,  # predefined ontology\n",
    "                              max_seq_length=64,  # 각 turn마다 최대 길이\n",
    "                              max_turn_length=max_turn)  # 각 dialogue의 최대 turn 길이\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zrIVLPMd6B7r",
    "outputId": "e2b46db4-4bc0-48b2-b23b-577fe3678543",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6301\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))  # 대화 level의 features\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowy-hat-8324:관광_식당_11\n",
      "8\n",
      "34\n",
      "64\n",
      "34\n",
      "34\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "f = train_features[0]\n",
    "\n",
    "print(f.guid)  # 대화 unique_id\n",
    "print(f.num_turn)  # 실제 대화의 turn 길이 == T\n",
    "print(len(f.input_ids))  # input_ids의 턴 길이 (max_turn_length == 현재 34)\n",
    "print(len(f.input_ids[0]))  # input_ids에서 각 턴의 최대 길이 (max_seq_length == 64)\n",
    "print(len(f.segment_ids))  # segment_ids의 턴 길이 (max_turn_length == 34)\n",
    "print(len(f.target_ids))  # target_ids의 갯수 (턴마다의 State == max_turn_length == 34)\n",
    "print(len(f.target_ids[0]))  # 각 턴마다 target의 갯수 == number of Slot Meta (== 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a3j7tb96B7r"
   },
   "source": [
    "## SUMBT 모델 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-IjCE6Db6B7r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most of code is from https://github.com/SKTBrain/SUMBT\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CosineEmbeddingLoss, CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "\n",
    "\n",
    "class BertForUtteranceEncoding(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForUtteranceEncoding, self).__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        return self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scores = None\n",
    "\n",
    "    def attention(self, q, k, v, d_k, mask=None, dropout=None):\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            scores = dropout(scores)\n",
    "\n",
    "        self.scores = scores\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # perform linear operation and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        scores = self.attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        return output\n",
    "\n",
    "    def get_scores(self):\n",
    "        return self.scores\n",
    "\n",
    "\n",
    "class SUMBT(nn.Module):\n",
    "    def __init__(self, args, num_labels, device):  # num_labels : # of Candidate values per each Slot\n",
    "        super(SUMBT, self).__init__()\n",
    "\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.rnn_num_layers = args.num_rnn_layers\n",
    "        self.zero_init_rnn = args.zero_init_rnn\n",
    "        self.max_seq_length = args.max_seq_length\n",
    "        self.max_label_length = args.max_label_length\n",
    "        self.num_labels = num_labels\n",
    "        self.num_slots = len(num_labels)\n",
    "        self.attn_head = args.attn_head\n",
    "        self.device = device\n",
    "\n",
    "        ### Utterance Encoder\n",
    "        self.utterance_encoder = BertForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        self.bert_output_dim = self.utterance_encoder.config.hidden_size\n",
    "        self.hidden_dropout_prob = self.utterance_encoder.config.hidden_dropout_prob\n",
    "        if args.fix_utterance_encoder:\n",
    "            for p in self.utterance_encoder.bert.pooler.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        ### slot, slot-value Encoder (not trainable)\n",
    "        self.sv_encoder = BertForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        # os.path.join(args.bert_dir, 'bert-base-uncased.model'))\n",
    "        for p in self.sv_encoder.bert.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.slot_lookup = nn.Embedding(self.num_slots, self.bert_output_dim)\n",
    "        self.value_lookup = nn.ModuleList(\n",
    "            [nn.Embedding(num_label, self.bert_output_dim) for num_label in num_labels]\n",
    "        )\n",
    "\n",
    "        ### Attention layer\n",
    "        self.attn = MultiHeadAttention(self.attn_head, self.bert_output_dim, dropout=0)\n",
    "\n",
    "        ### RNN Belief Tracker\n",
    "        self.nbt = nn.GRU(\n",
    "            input_size=self.bert_output_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.rnn_num_layers,\n",
    "            dropout=self.hidden_dropout_prob,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.init_parameter(self.nbt)\n",
    "\n",
    "        if not self.zero_init_rnn:\n",
    "            self.rnn_init_linear = nn.Sequential(\n",
    "                nn.Linear(self.bert_output_dim, self.hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.hidden_dropout_prob),\n",
    "            )\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.bert_output_dim)\n",
    "        self.layer_norm = nn.LayerNorm(self.bert_output_dim)\n",
    "\n",
    "        ### Measure\n",
    "#         self.metric = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
    "        self.distance_metric = args.distance_metric\n",
    "        if self.distance_metric == \"cosine\":\n",
    "            self.metric = torch.nn.CosineSimilarity(dim=-1, eps=1e-08)\n",
    "        elif self.distance_metric == \"euclidean\":\n",
    "            self.metric = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
    "\n",
    "        ### Classifier\n",
    "        self.nll = CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        ### Etc.\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "\n",
    "    def initialize_slot_value_lookup(self, label_ids, slot_ids):\n",
    "\n",
    "        self.sv_encoder.eval()\n",
    "\n",
    "        # Slot encoding\n",
    "        slot_type_ids = torch.zeros(slot_ids.size(), dtype=torch.long).to(\n",
    "            slot_ids.device\n",
    "        )\n",
    "        slot_mask = slot_ids > 0\n",
    "        hid_slot, _ = self.sv_encoder(\n",
    "            slot_ids.view(-1, self.max_label_length),\n",
    "            slot_type_ids.view(-1, self.max_label_length),\n",
    "            slot_mask.view(-1, self.max_label_length),\n",
    "        )\n",
    "        hid_slot = hid_slot[:, 0, :]\n",
    "        hid_slot = hid_slot.detach()\n",
    "        self.slot_lookup = nn.Embedding.from_pretrained(hid_slot, freeze=True)\n",
    "\n",
    "        for s, label_id in enumerate(label_ids):\n",
    "            label_type_ids = torch.zeros(label_id.size(), dtype=torch.long).to(\n",
    "                label_id.device\n",
    "            )\n",
    "            label_mask = label_id > 0\n",
    "            hid_label, _ = self.sv_encoder(\n",
    "                label_id.view(-1, self.max_label_length),\n",
    "                label_type_ids.view(-1, self.max_label_length),\n",
    "                label_mask.view(-1, self.max_label_length),\n",
    "            )\n",
    "            hid_label = hid_label[:, 0, :]\n",
    "            hid_label = hid_label.detach()\n",
    "            self.value_lookup[s] = nn.Embedding.from_pretrained(hid_label, freeze=True)\n",
    "            self.value_lookup[s].padding_idx = -1\n",
    "\n",
    "        print(\"Complete initialization of slot and value lookup\")\n",
    "        self.sv_encoder = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        token_type_ids,\n",
    "        attention_mask,\n",
    "        labels=None,\n",
    "        n_gpu=1,\n",
    "        target_slot=None,\n",
    "    ):\n",
    "        # B: Batch size, M: Max turn length, N: Max seq length, \n",
    "        # J: # of Slot Meta, H: Hidden dimension\n",
    "        \n",
    "        # input_ids: [B, M, N]\n",
    "        # token_type_ids: [B, M, N]\n",
    "        # attention_mask: [B, M, N]\n",
    "        # labels: [B, M, J]\n",
    "\n",
    "        # if target_slot is not specified, output values corresponding all slot-types\n",
    "        if target_slot is None:\n",
    "            target_slot = list(range(0, self.num_slots))\n",
    "\n",
    "        ds = input_ids.size(0)  # Batch size (B)\n",
    "        ts = input_ids.size(1)  # Max turn size (M)\n",
    "        bs = ds * ts\n",
    "        slot_dim = len(target_slot)  # J\n",
    "\n",
    "        # Utterance encoding\n",
    "        # Utterence-level로 독립적으로 인코딩하므로 flatten필요\n",
    "        hidden, _ = self.utterance_encoder(\n",
    "            input_ids.view(-1, self.max_seq_length),\n",
    "            token_type_ids.view(-1, self.max_seq_length),\n",
    "            attention_mask.view(-1, self.max_seq_length),\n",
    "        )\n",
    "        hidden = torch.mul(\n",
    "            hidden,\n",
    "            attention_mask.view(-1, self.max_seq_length, 1)\n",
    "            .expand(hidden.size())\n",
    "            .float(),\n",
    "        )\n",
    "        hidden = hidden.repeat(slot_dim, 1, 1)  # [J*M*B, N, H]\n",
    "\n",
    "        hid_slot = self.slot_lookup.weight[target_slot, :]  # Select target slot embedding\n",
    "        hid_slot = hid_slot.repeat(1, bs).view(bs * slot_dim, -1)  # [J*M*B, N, H]\n",
    "\n",
    "        # Attended utterance vector\n",
    "        hidden = self.attn(\n",
    "            hid_slot,  # q^s  [J*M*B, N, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            mask=attention_mask.view(-1, 1, self.max_seq_length).repeat(slot_dim, 1, 1),\n",
    "        )\n",
    "        hidden = hidden.squeeze()  # h [J*M*B, H] Aggregated Slot Context\n",
    "        hidden = hidden.view(slot_dim, ds, ts, -1).view(-1, ts, self.bert_output_dim)  # [J*B, M, H]\n",
    "\n",
    "        # NBT\n",
    "        if self.zero_init_rnn:\n",
    "            h = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "        else:\n",
    "            h = hidden[:, 0, :].unsqueeze(0).repeat(self.rnn_num_layers, 1, 1)\n",
    "            h = self.rnn_init_linear(h)\n",
    "\n",
    "        if isinstance(self.nbt, nn.GRU):\n",
    "            rnn_out, _ = self.nbt(hidden, h)  # [J*B, M, H_GRU]\n",
    "        elif isinstance(self.nbt, nn.LSTM):\n",
    "            c = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "            rnn_out, _ = self.nbt(hidden, (h, c))  # [slot_dim*ds, turn, hidden]\n",
    "        rnn_out = self.layer_norm(self.linear(self.dropout(rnn_out)))\n",
    "\n",
    "        hidden = rnn_out.view(slot_dim, ds, ts, -1)  # [J, B, M, H_GRU]\n",
    "\n",
    "        # Label (slot-value) encoding\n",
    "        loss = 0\n",
    "        loss_slot = []\n",
    "        pred_slot = []\n",
    "        output = []\n",
    "        for s, slot_id in enumerate(target_slot):  ## note: target_slots are successive\n",
    "            # loss calculation\n",
    "            hid_label = self.value_lookup[slot_id].weight\n",
    "            num_slot_labels = hid_label.size(0)\n",
    "\n",
    "            _hid_label = (\n",
    "                hid_label.unsqueeze(0)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(ds, ts, 1, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _hidden = (\n",
    "                hidden[s, :, :, :]\n",
    "                .unsqueeze(2)\n",
    "                .repeat(1, 1, num_slot_labels, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _dist = self.metric(_hid_label, _hidden).view(ds, ts, num_slot_labels)\n",
    "            if self.distance_metric == \"euclidean\":\n",
    "                _dist = -_dist\n",
    "            _, pred = torch.max(_dist, -1)  # taget_ids에서 ignore index 즉, padding일 경우 -1로 setting했었음\n",
    "            pred_slot.append(pred.view(ds, ts, 1))\n",
    "            output.append(_dist)\n",
    "\n",
    "            if labels is not None:\n",
    "                _loss = self.nll(_dist.view(ds * ts, -1), labels[:, :, s].view(-1))\n",
    "                loss_slot.append(_loss.item())\n",
    "                loss += _loss\n",
    "\n",
    "        pred_slot = torch.cat(pred_slot, 2)\n",
    "        if labels is None:\n",
    "            return output, pred_slot\n",
    "\n",
    "        # calculate joint accuracy\n",
    "        accuracy = (pred_slot == labels).view(-1, slot_dim)\n",
    "        acc_slot = (\n",
    "            torch.sum(accuracy, 0).float()\n",
    "            / torch.sum(labels.view(-1, slot_dim) > -1, 0).float()\n",
    "        )\n",
    "        acc = (\n",
    "            sum(torch.sum(accuracy, 1) / slot_dim).float()\n",
    "            / torch.sum(labels[:, :, 0].view(-1) > -1, 0).float()\n",
    "        )  # joint accuracy\n",
    "\n",
    "        if n_gpu == 1:\n",
    "            return loss, loss_slot, acc, acc_slot, pred_slot\n",
    "        else:\n",
    "            return (\n",
    "                loss.unsqueeze(0),\n",
    "                None,\n",
    "                acc.unsqueeze(0),\n",
    "                acc_slot.unsqueeze(0),\n",
    "                pred_slot.unsqueeze(0),\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def init_parameter(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(module.weight)\n",
    "            torch.nn.init.constant_(module.bias, 0.0)\n",
    "        elif isinstance(module, nn.GRU) or isinstance(module, nn.LSTM):\n",
    "            torch.nn.init.xavier_normal_(module.weight_ih_l0)\n",
    "            torch.nn.init.xavier_normal_(module.weight_hh_l0)\n",
    "            torch.nn.init.constant_(module.bias_ih_l0, 0.0)\n",
    "            torch.nn.init.constant_(module.bias_hh_l0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYm56GEZ6B7u"
   },
   "source": [
    "## TODO-2: Ontology Pre-Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WdPyqp16B7w"
   },
   "source": [
    "Ontology의 slot type들과 이에 속하는 slot_value들을 tokenizing하는 `tokenize_ontology`를 작성하세요. <br>\n",
    "[CLS] Pooling하여 `slot_lookup` 과 `value_lookup` embedding matrix들을 초기화하는 <br>\n",
    "`initialize_slot_value_lookup`에 인자로 넘겨주세요. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zwgNUZNn6B7w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_ontology(ontology, tokenizer, max_seq_length=12):\n",
    "    slot_types = []\n",
    "    slot_values = []\n",
    "    for k, v in ontology.items():\n",
    "        tokens = tokenizer.encode(k)\n",
    "        if len(tokens) < max_seq_length:\n",
    "            gap = max_seq_length - len(tokens)\n",
    "            tokens.extend([tokenizer.pad_token_id] *  gap)\n",
    "        slot_types.append(tokens)\n",
    "        slot_value = []\n",
    "        for vv in v:\n",
    "            tokens = tokenizer.encode(vv)\n",
    "            if len(tokens) < max_seq_length:\n",
    "                gap = max_seq_length - len(tokens)\n",
    "                tokens.extend([tokenizer.pad_token_id] *  gap)\n",
    "            slot_value.append(tokens)\n",
    "        slot_values.append(torch.LongTensor(slot_value))\n",
    "    return torch.LongTensor(slot_types), slot_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "attmAW3A6B7w",
    "outputId": "9dbf4e3d-f077-4782-9d3b-d7c8c00159ff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4, 4, 103, 13, 4, 7, 5, 4, 4, 4, 12, 12, 9, 67, 4, 4, 7, 4, 7, 4, 4, 5, 4, 4, 12, 569, 9, 44, 4, 10, 4, 4, 7, 4, 60, 12, 60, 190, 298, 5, 431, 286]\n",
      "Tokenized Slot:  torch.Size([45, 12])\n",
      "Tokenized Value of 관광-경치 좋은 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-교육적 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-문화 예술 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-역사적 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-이름 torch.Size([103, 12])\n",
      "Tokenized Value of 관광-종류 torch.Size([13, 12])\n",
      "Tokenized Value of 관광-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-가격대 torch.Size([5, 12])\n",
      "Tokenized Value of 숙소-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-수영장 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-스파 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-예약 기간 torch.Size([12, 12])\n",
      "Tokenized Value of 숙소-예약 명수 torch.Size([12, 12])\n",
      "Tokenized Value of 숙소-예약 요일 torch.Size([9, 12])\n",
      "Tokenized Value of 숙소-이름 torch.Size([67, 12])\n",
      "Tokenized Value of 숙소-인터넷 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-조식 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-종류 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-헬스장 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-흡연 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-가격대 torch.Size([5, 12])\n",
      "Tokenized Value of 식당-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-야외석 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-예약 명수 torch.Size([12, 12])\n",
      "Tokenized Value of 식당-예약 시간 torch.Size([569, 12])\n",
      "Tokenized Value of 식당-예약 요일 torch.Size([9, 12])\n",
      "Tokenized Value of 식당-이름 torch.Size([44, 12])\n",
      "Tokenized Value of 식당-인터넷 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-종류 torch.Size([10, 12])\n",
      "Tokenized Value of 식당-주류 판매 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 식당-흡연 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 지하철-도착지 torch.Size([60, 12])\n",
      "Tokenized Value of 지하철-출발 시간 torch.Size([12, 12])\n",
      "Tokenized Value of 지하철-출발지 torch.Size([60, 12])\n",
      "Tokenized Value of 택시-도착 시간 torch.Size([190, 12])\n",
      "Tokenized Value of 택시-도착지 torch.Size([298, 12])\n",
      "Tokenized Value of 택시-종류 torch.Size([5, 12])\n",
      "Tokenized Value of 택시-출발 시간 torch.Size([431, 12])\n",
      "Tokenized Value of 택시-출발지 torch.Size([286, 12])\n"
     ]
    }
   ],
   "source": [
    "slot_type_ids, slot_values_ids = tokenize_ontology(ontology, tokenizer, 12)\n",
    "num_labels = [len(s) for s in slot_values_ids]  # 각 Slot 별 후보 Values의 갯수\n",
    "print(num_labels)\n",
    "print(\"Tokenized Slot: \", slot_type_ids.size())\n",
    "for slot, slot_value_id in zip(slot_meta, slot_values_ids):\n",
    "    print(f\"Tokenized Value of {slot}\", slot_value_id.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCsCGN0f6B7x"
   },
   "source": [
    "## Model 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aQSRYG6e6B7x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# argsparse 있던 위치\n",
    "\n",
    "num_labels = [len(s) for s in slot_values_ids]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = 1 if torch.cuda.device_count() < 2 else torch.cuda.device_count()\n",
    "n_epochs = args.num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NZNUF9k86B7x",
    "outputId": "4ef347fd-6fa1-4f26-e8a4-8133614f9380",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = SUMBT(args, num_labels, device)\n",
    "# model.initialize_slot_value_lookup(slot_values_ids, slot_type_ids)  # Tokenized Ontology의 Pre-encoding using BERT_SV\n",
    "# model.to(device)\n",
    "\n",
    "# wandb.watch(model)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulJJGp5a6B7x"
   },
   "source": [
    "## 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yBU7KP5A6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data_utils import WOSDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, sampler=train_sampler, collate_fn=processor.collate_fn)\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, batch_size=8, sampler=dev_sampler, collate_fn=processor.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVQC_XUG6B7y"
   },
   "source": [
    "## Optimizer & Scheduler 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wK-LWnHU6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "# optimizer_grouped_parameters = [\n",
    "#         {\n",
    "#             \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#             \"weight_decay\": args.weight_decay,\n",
    "#         },\n",
    "#         {\n",
    "#             \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#             \"weight_decay\": 0.0,\n",
    "#         },\n",
    "#     ]\n",
    "\n",
    "# t_total = len(train_loader) * n_epochs\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps=int(t_total * args.warmup_ratio), num_training_steps=t_total\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-f0L44h6B7y"
   },
   "source": [
    "## TODO-3: Inference code 작성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jCGuenx36B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluation import _evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LBXWTFHi6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, eval_loader, processor, device):\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    for batch in eval_loader:\n",
    "        input_ids, segment_ids, input_masks, target_ids, num_turns, guids = \\\n",
    "        [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, pred_slot = model(\n",
    "                input_ids, segment_ids, input_masks, labels=None, n_gpu=1\n",
    "            )\n",
    "        \n",
    "        batch_size = input_ids.size(0)\n",
    "        for i in range(batch_size):\n",
    "            guid = guids[i]\n",
    "            states = processor.recover_state(pred_slot.tolist()[i], num_turns[i])\n",
    "            for tid, state in enumerate(states):\n",
    "                predictions[f\"{guid}-{tid}\"] = state\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW-qyUd_6B7y"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('20epoch.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "S7tpx4426B7z",
    "outputId": "9538d5cc-c271-4176-e1a1-af2d1121c40c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "    \n",
    "        model = SUMBT(args, num_labels, device)\n",
    "        model.initialize_slot_value_lookup(slot_values_ids, slot_type_ids)  # Tokenized Ontology의 Pre-encoding using BERT_SV\n",
    "        model.to(device)\n",
    "\n",
    "        wandb.watch(model)\n",
    "        \n",
    "        \n",
    "        # for checkpoint management\n",
    "        chk_list = []\n",
    "        output_dir = increment_output_dir(wandb.run.name)\n",
    "        \n",
    "        if not os.path.exists(f\"checkpoint/{output_dir}\"):\n",
    "            os.makedirs(f\"checkpoint/{output_dir}\")\n",
    "\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": args.weight_decay,\n",
    "                },\n",
    "                {\n",
    "                    \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                    \"weight_decay\": 0.0,\n",
    "                },\n",
    "            ]\n",
    "\n",
    "        t_total = len(train_loader) * n_epochs\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=int(t_total * args.warmup_ratio), num_training_steps=t_total\n",
    "        )            \n",
    "        \n",
    "        \n",
    "        best_score, best_checkpoint = 0, 0\n",
    "        for epoch in range(n_epochs):\n",
    "            batch_loss = []\n",
    "            batch_loss_per_100step = []\n",
    "            for step, batch in enumerate(tqdm(train_loader)):\n",
    "                model.train()\n",
    "                input_ids, segment_ids, input_masks, target_ids, num_turns, guids  = \\\n",
    "                [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "\n",
    "                # Forwabatch_size        \n",
    "                if n_gpu == 1:\n",
    "                    loss, loss_slot, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "                else:\n",
    "                    loss, _, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "\n",
    "                batch_loss.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                if step % 100 == 0 or step == len(train_loader):\n",
    "                    batch_loss_per_100step.append(loss.item())\n",
    "                    print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(train_loader), loss.item()))\n",
    "                    # epoch를 마쳤거나, 최저 loss 갱신했을 때 추론\n",
    "                    if step == len(train_loader) or min(batch_loss_per_100step) >= loss.item():\n",
    "                        print('inferencing')\n",
    "                        predictions = inference(model, dev_loader, processor, device)\n",
    "                        eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "                        current_score = eval_result['joint_goal_accuracy']\n",
    "\n",
    "                        if best_score < current_score:\n",
    "                            best_score = current_score\n",
    "                            print('new best JGA score! ', best_score)\n",
    "                            \n",
    "                            # checkpoint 수 관리\n",
    "                            if len(chk_list) >= 1:\n",
    "                                os.remove(chk_list.pop(0))\n",
    "                            \n",
    "                            output_path = f\"checkpoint/{output_dir}/{epoch}_{step}_{best_score}.pth\"\n",
    "                            chk_list.append(output_path)\n",
    "                            \n",
    "                            torch.save({\n",
    "                                        'epoch': epoch,\n",
    "                                        'model_state_dict': model.state_dict(),\n",
    "                                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                        'loss': loss,\n",
    "                                        }, output_path)\n",
    "                        for k, v in eval_result.items():\n",
    "                            print(f\"{k}: {v}\")\n",
    "                        wandb.log({\n",
    "                            \"loss\": loss.item(),\n",
    "                            \"Joint Goal Accuracy\": eval_result['joint_goal_accuracy'],\n",
    "                            \"Turn Slot_Accuracy\": eval_result['turn_slot_accuracy'],\n",
    "                            \"Turn Slot F1\": eval_result['turn_slot_f1']\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaepd\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cool-firebrand-72</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/taepd/SUMBT-sweep\" target=\"_blank\">https://wandb.ai/taepd/SUMBT-sweep</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/taepd/SUMBT-sweep/runs/uqagwn3m\" target=\"_blank\">https://wandb.ai/taepd/SUMBT-sweep/runs/uqagwn3m</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/repo/taepd/code/notebooks/wandb/run-20210502_114545-uqagwn3m</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete initialization of slot and value lookup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [0/701] 122.612656\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:06:28, 31.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.0, 'turn_slot_accuracy': 0.03879146141215199, 'turn_slot_f1': 0.05740321942804178}\n",
      "joint_goal_accuracy: 0.0\n",
      "turn_slot_accuracy: 0.03879146141215199\n",
      "turn_slot_f1: 0.05740321942804178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 100/701 [02:27<11:42,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [100/701] 35.868423\n",
      "inferencing\n",
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8189512862616227, 'turn_slot_f1': 0.07097171949143095}\n",
      "new best JGA score!  0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [03:00<1:47:54, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8189512862616227\n",
      "turn_slot_f1: 0.07097171949143095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 200/701 [04:57<09:50,  1.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [200/701] 23.888100\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [05:28<1:25:03, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8444575807334431, 'turn_slot_f1': 0.18802284592637017}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8444575807334431\n",
      "turn_slot_f1: 0.18802284592637017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [07:25<07:47,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [300/701] 25.586157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [09:22<05:54,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [400/701] 24.964899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [11:19<03:53,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [500/701] 31.384569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [13:16<01:56,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [600/701] 35.662365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [15:12<00:00,  1.30s/it]\n",
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [700/701] 36.874531\n",
      "[1/10] [0/701] 39.812473\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:02:21, 31.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205276409414228, 'turn_slot_f1': 0.01939238901852332}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205276409414228\n",
      "turn_slot_f1: 0.01939238901852332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 100/701 [02:26<11:41,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [100/701] 32.761971\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [02:57<1:41:24, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [04:54<09:44,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [200/701] 34.916893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [06:51<07:52,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [300/701] 34.771412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [08:48<05:50,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [400/701] 37.532112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 500/701 [10:43<03:54,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [500/701] 32.596970\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [11:14<33:49, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [13:11<01:56,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [600/701] 34.144550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 700/701 [15:07<00:01,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] [700/701] 24.290779\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [15:37<00:00,  1.34s/it]\n",
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n",
      "[2/10] [0/701] 35.246906\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:02:46, 31.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [02:28<11:41,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [100/701] 36.169003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 200/701 [04:24<09:45,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [200/701] 34.149017\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [04:55<1:24:33, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [06:52<07:46,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [300/701] 35.122711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [08:49<05:55,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [400/701] 36.470959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 500/701 [10:45<03:55,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [500/701] 27.432068\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [11:16<33:49, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [13:13<01:57,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [600/701] 35.423752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [15:09<00:00,  1.30s/it]\n",
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] [700/701] 34.213127\n",
      "[3/10] [0/701] 33.465466\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:02:43, 31.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [02:27<11:38,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [100/701] 36.342976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 200/701 [04:23<09:44,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [200/701] 32.358261\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [04:54<1:24:28, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [06:51<07:47,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [300/701] 35.618248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [08:48<05:50,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [400/701] 34.637234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [10:45<03:53,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [500/701] 36.655827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [12:41<01:56,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [600/701] 35.151821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 700/701 [14:37<00:01,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] [700/701] 30.428123\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [15:07<00:00,  1.30s/it]\n",
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n",
      "[4/10] [0/701] 32.695244\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:02:29, 31.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [02:28<11:42,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [100/701] 37.511578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [04:25<09:45,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [200/701] 36.246857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [06:22<07:47,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [300/701] 36.969002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [08:18<05:50,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [400/701] 34.116360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [10:15<03:52,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [500/701] 35.689556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [12:12<01:56,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [600/701] 33.802326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [14:08<00:00,  1.21s/it]\n",
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] [700/701] 39.050247\n",
      "[5/10] [0/701] 35.670254\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:02:40, 31.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 100/701 [02:26<11:45,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [100/701] 30.464821\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [02:57<1:41:30, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [04:54<09:49,  1.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [200/701] 33.168449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 300/701 [06:50<07:46,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [300/701] 28.833149\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [07:21<1:07:34, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [09:18<05:50,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [400/701] 31.744993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [11:14<03:53,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [500/701] 33.557621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [13:11<01:56,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [600/701] 35.683952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [15:06<00:00,  1.29s/it]\n",
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] [700/701] 32.338913\n",
      "[6/10] [0/701] 32.260563\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:02:45, 31.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [02:27<11:40,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [100/701] 34.853958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [04:24<09:44,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [200/701] 35.475788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [06:21<07:47,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [300/701] 35.530464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [08:18<05:51,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [400/701] 33.600800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [10:15<03:53,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [500/701] 33.968369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [12:12<01:56,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [600/701] 37.164165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [14:08<00:00,  1.21s/it]\n",
      "  0%|          | 0/701 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] [700/701] 34.885460\n",
      "[7/10] [0/701] 36.625496\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/701 [00:31<6:02:38, 31.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 100/701 [02:27<11:46,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] [100/701] 30.464228\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 101/701 [02:58<1:41:31, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 201/701 [04:55<09:44,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] [200/701] 34.585785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 300/701 [06:50<07:48,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] [300/701] 27.087782\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 301/701 [07:21<1:07:37, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.019310344827586208, 'turn_slot_accuracy': 0.8205363984674218, 'turn_slot_f1': 0.019310344827586208}\n",
      "joint_goal_accuracy: 0.019310344827586208\n",
      "turn_slot_accuracy: 0.8205363984674218\n",
      "turn_slot_f1: 0.019310344827586208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 401/701 [09:18<05:50,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] [400/701] 32.752735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 501/701 [11:15<03:53,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] [500/701] 32.557796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 601/701 [13:12<01:56,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] [600/701] 35.538612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 658/701 [14:20<00:56,  1.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23069<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/opt/ml/repo/taepd/code/notebooks/wandb/run-20210502_114545-uqagwn3m/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/opt/ml/repo/taepd/code/notebooks/wandb/run-20210502_114545-uqagwn3m/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>27.08778</td></tr><tr><td>Joint Goal Accuracy</td><td>0.01931</td></tr><tr><td>Turn Slot_Accuracy</td><td>0.82054</td></tr><tr><td>Turn Slot F1</td><td>0.01931</td></tr><tr><td>_runtime</td><td>6736</td></tr><tr><td>_timestamp</td><td>1619962681</td></tr><tr><td>_step</td><td>20</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>█▂▁▂▂▂▁▂▂▁▂▂▁▂▂▁▁▂▂▁▁</td></tr><tr><td>Joint Goal Accuracy</td><td>▁████████████████████</td></tr><tr><td>Turn Slot_Accuracy</td><td>▁████████████████████</td></tr><tr><td>Turn Slot F1</td><td>▃▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▃▃▃▃▄▄▄▅▅▆▆▆▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▃▃▃▃▄▄▄▅▅▆▆▆▇███</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cool-firebrand-72</strong>: <a href=\"https://wandb.ai/taepd/SUMBT-sweep/runs/uqagwn3m\" target=\"_blank\">https://wandb.ai/taepd/SUMBT-sweep/runs/uqagwn3m</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2aa6fb868e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# noraml train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-c91a7e469e41>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=10)\n",
    "# wandb.agent('kxb5gf1d', train, count=1)\n",
    "\n",
    "# noraml train\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete initialization of slot and value lookup\n"
     ]
    }
   ],
   "source": [
    "# model = SUMBT(args, num_labels, device)\n",
    "# model.initialize_slot_value_lookup(slot_values_ids, slot_type_ids)  # Tokenized Ontology의 Pre-encoding using BERT_SV\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "# no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "# optimizer_grouped_parameters = [\n",
    "#         {\n",
    "#             \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#             \"weight_decay\": args.weight_decay,\n",
    "#         },\n",
    "#         {\n",
    "#             \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#             \"weight_decay\": 0.0,\n",
    "#         },\n",
    "#     ]\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n",
    "\n",
    "# PATH = 'checkpoint/solar-sweep-3/9_700_0.7885714285714286.pth'\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# model1.load_state_dict(torch.load('checkpoint/solar-sweep-3/9_700_0.7885714285714286.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHUyY11B6B70"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "VzusVESG6B70",
    "outputId": "972f9d9f-336e-452d-c535-0aef4638f40f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2493.76it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/repo/taepd/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=True, dialogue_level=True\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "88F6j_5v6B71",
    "outputId": "9fdd691f-2974-47d4-f71c-fd454048f9eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1-IQhzx16B71"
   },
   "outputs": [],
   "source": [
    "json.dump(predictions, open('predictions.csv', 'w'), indent=2, ensure_ascii=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SUMBT.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
