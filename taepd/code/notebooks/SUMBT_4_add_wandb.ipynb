{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sumbt_baseline(single train)\n",
    "- checkpoint\n",
    "    - add checkpoint\n",
    "    - add checkpoint saving process\n",
    "    - update checkpoint type(available countinous training)\n",
    "- update validation per epoch or minimal loss\n",
    "- add wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Koaz3guQ6B7k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "from data_utils import get_examples_from_dialogues, convert_state_dict, load_dataset\n",
    "from data_utils import OntologyDSTFeature, DSTPreprocessor, _truncate_seq_pair\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# !wandb login  # run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_output_dir(output_path, exist_ok=False):\n",
    "  path = Path(output_path)\n",
    "  if (path.exists() and exist_ok) or (not path.exists()):\n",
    "    return str(path)\n",
    "  else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" %path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### argparse setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'batch_size': 8,  # 8\n",
    "    'hidden_dim': 300,\n",
    "    'num_rnn_layers': 1,\n",
    "    'zero_init_rnn': False,\n",
    "    'max_seq_length': 64,\n",
    "    'max_label_length': 12,\n",
    "    'attn_head': 8,  # 4\n",
    "    'fix_utterance_encoder': False,\n",
    "    'task_name': 'sumbtgru',\n",
    "    'distance_metric': 'euclidean',\n",
    "    'model_name_or_path': 'dsksd/bert-ko-small-minimal',\n",
    "    'warmup_ratio': 0.1,\n",
    "    'learning_rate': 1e-4,  # 5e-5, \n",
    "    'weight_decay': 0.001,  # 0.01\n",
    "    'num_train_epochs': 25\n",
    "}\n",
    "\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaepd\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">devout-vortex-92</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/taepd/SUMBT-sweep\" target=\"_blank\">https://wandb.ai/taepd/SUMBT-sweep</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/taepd/SUMBT-sweep/runs/13xvzd2o\" target=\"_blank\">https://wandb.ai/taepd/SUMBT-sweep/runs/13xvzd2o</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/repo/taepd/code/notebooks/wandb/run-20210521_014106-13xvzd2o</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb sweep 생성 시 parameters에 전달하는 config 설정\n",
    "hyperparameter_defaults = dict(\n",
    "    batch_size = args.batch_size,\n",
    "    learning_rate = args.learning_rate,\n",
    "    epochs = args.num_train_epochs,\n",
    "    weight_decay = args.weight_decay,\n",
    "    attn_head = args.attn_head,\n",
    "    distance_metric = args.distance_metric,\n",
    "    \n",
    "#     dropout = 0.1,\n",
    "#     smoothing = 0.2\n",
    "#     model_name = 'BertForSequenceClassification',\n",
    "#     tokenizer_name = 'BertTokenizer',\n",
    "    )\n",
    "\n",
    "wandb.init(config=hyperparameter_defaults, project=\"SUMBT-sweep\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wandb sweep config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_config = {\n",
    "#   \"name\": \"SUMBT-sweep\",\n",
    "#   \"method\": \"bayes\",\n",
    "#   \"metric\": {\n",
    "#       \"goal\": \"maximize\",\n",
    "#       \"name\": \"Joint Goal Accuracy\"},\n",
    "#   \"parameters\": {\n",
    "#       \"attn_head\": {\n",
    "#           \"distribution\": \"int_uniform\",\n",
    "#           \"max\": 12,\n",
    "#           \"min\": 4\n",
    "#       },\n",
    "#       \"batch_size\": {\n",
    "#           \"distribution\": \"int_uniform\",\n",
    "#           \"max\": 12,\n",
    "#           \"min\": 8\n",
    "#       },\n",
    "#       \"distance_metric\": {\n",
    "#           \"distribution\": \"categorical\",\n",
    "#           \"values\": [\"euclidean\", \"cosine\"]\n",
    "#       },\n",
    "#       \"learning_rate\": {\n",
    "#           \"distribution\": \"uniform\",\n",
    "#           \"max\": 1e-03,\n",
    "#           \"min\": 5e-05\n",
    "#       },\n",
    "#       \"weight_decay\": {\n",
    "#           \"distribution\": \"uniform\",\n",
    "#           \"max\": 0.02,\n",
    "#           \"min\": 0.005\n",
    "#       }\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # sweep_id = wandb.sweep(sweep_config, project=\"SUMBT-sweep\")\n",
    "# # sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU        \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCYa_jbt6B7m"
   },
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "y2Jpgv4i6B7n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_file = \"/opt/ml/repo/taepd/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/ontology_aug.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Vu232Prn6B7n",
    "outputId": "a17014f7-81fd-41c6-c4e6-c4958942a45e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 8482.53it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 15836.97it/s]\n"
     ]
    }
   ],
   "source": [
    "train_examples = get_examples_from_dialogues(data=train_data,\n",
    "                                             user_first=True,\n",
    "                                             dialogue_level=True)\n",
    "\n",
    "dev_examples = get_examples_from_dialogues(data=dev_data,\n",
    "                                           user_first=True,\n",
    "                                           dialogue_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aGKZk4_n6B7o",
    "outputId": "5502faa6-a80f-496a-fe8f-399ecd62350f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6301"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1qqe5Hw36B7o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_turn = max([len(e['dialogue']) for e in train_data])\n",
    "tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(max_turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq2fddAg6B7p"
   },
   "source": [
    "## TODO-1: SUMBT Preprocessor 정의 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCoRCk1z6B7p"
   },
   "source": [
    "Ontology-based DST model인 SUMBT의 InputFeature를 만들기 위한 Preprocessor를 정의해야 합니다. <br>\n",
    "\n",
    "1. `_convert_examples_to_features` 함수의 빈칸을 매워 완성하세요.\n",
    "2. `recover_state` 함수의 빈칸을 매워 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p8MjYjqw6B7p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SUMBTPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=64,\n",
    "        max_turn_length=12,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_turn_length = max_turn_length\n",
    "\n",
    "    def _convert_example_to_feature(self, example):\n",
    "        guid = example[0].guid.rsplit(\"-\", 1)[0]  # dialogue_idx\n",
    "        turns = []\n",
    "        token_types = []\n",
    "        labels = []\n",
    "        num_turn = None\n",
    "        for turn in example[: self.max_turn_length]:\n",
    "            assert len(turn.current_turn) == 2\n",
    "            uttrs = []\n",
    "            for segment_idx, uttr in enumerate(turn.current_turn):\n",
    "                token = self.src_tokenizer.encode(uttr, add_special_tokens=False)\n",
    "                uttrs.append(token)\n",
    "\n",
    "            _truncate_seq_pair(uttrs[0], uttrs[1], self.max_seq_length - 3)\n",
    "            tokens = (\n",
    "                [self.src_tokenizer.cls_token_id]\n",
    "                + uttrs[0]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "                + uttrs[1]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "            )\n",
    "            token_type = [0] * (len(uttrs[0]) + 2) + [1] * (len(uttrs[1]) + 1)\n",
    "            if len(tokens) < self.max_seq_length:\n",
    "                gap = self.max_seq_length - len(tokens)\n",
    "                tokens.extend([self.src_tokenizer.pad_token_id] * gap)\n",
    "                token_type.extend([0] * gap)\n",
    "            turns.append(tokens)\n",
    "            token_types.append(token_type)\n",
    "            label = []\n",
    "            if turn.label:\n",
    "                slot_dict = convert_state_dict(turn.label)\n",
    "            else:\n",
    "                slot_dict = {}\n",
    "            for slot_type in self.slot_meta:\n",
    "                value = slot_dict.get(slot_type, \"none\")\n",
    "                # TODO\n",
    "                # raise Exception('label_idx를 ontology에서 꺼내오는 코드를 작성하세요!')\n",
    "#                 label_idx = self.ontology[slot_type].index(value)  # 이렇게 해도 될듯한데?\n",
    "                if value in self.ontology[slot_type]:\n",
    "                    label_idx = self.ontology[slot_type].index(value)\n",
    "                else:\n",
    "                    label_idx = self.ontology[slot_type].index(\"none\")\n",
    "                label.append(label_idx)\n",
    "            labels.append(label)\n",
    "        num_turn = len(turns)\n",
    "        if len(turns) < self.max_turn_length:\n",
    "            gap = self.max_turn_length - len(turns)\n",
    "            for _ in range(gap):\n",
    "                dummy_turn = [self.src_tokenizer.pad_token_id] * self.max_seq_length\n",
    "                turns.append(dummy_turn)\n",
    "                token_types.append(dummy_turn)\n",
    "                dummy_label = [-1] * len(self.slot_meta)\n",
    "                labels.append(dummy_label)\n",
    "        return OntologyDSTFeature(\n",
    "            guid=guid,\n",
    "            input_ids=turns,\n",
    "            segment_ids=token_types,\n",
    "            num_turn=num_turn,\n",
    "            target_ids=labels,\n",
    "        )\n",
    "\n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "    def recover_state(self, pred_slots, num_turn):\n",
    "        states = []\n",
    "        for pred_slot in pred_slots[:num_turn]:\n",
    "            state = []\n",
    "            for s, p in zip(self.slot_meta, pred_slot):\n",
    "                v = self.ontology[s][p]\n",
    "                if v != \"none\":\n",
    "                    state.append(f\"{s}-{v}\")\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor([b.input_ids for b in batch])\n",
    "        segment_ids = torch.LongTensor([b.segment_ids for b in batch])\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "        target_ids = torch.LongTensor([b.target_ids for b in batch])\n",
    "        num_turns = [b.num_turn for b in batch]\n",
    "        return input_ids, segment_ids, input_masks, target_ids, num_turns, guids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhFMIiFy6B7q"
   },
   "source": [
    "## Convert_Examples_to_Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EKluwCmH6B7r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = SUMBTPreprocessor(slot_meta,\n",
    "                              tokenizer,\n",
    "                              ontology=ontology,  # predefined ontology\n",
    "                              max_seq_length=64,  # 각 turn마다 최대 길이\n",
    "                              max_turn_length=max_turn)  # 각 dialogue의 최대 turn 길이\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zrIVLPMd6B7r",
    "outputId": "e2b46db4-4bc0-48b2-b23b-577fe3678543",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6301\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))  # 대화 level의 features\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowy-hat-8324:관광_식당_11\n",
      "8\n",
      "34\n",
      "64\n",
      "34\n",
      "34\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "f = train_features[0]\n",
    "\n",
    "print(f.guid)  # 대화 unique_id\n",
    "print(f.num_turn)  # 실제 대화의 turn 길이 == T\n",
    "print(len(f.input_ids))  # input_ids의 턴 길이 (max_turn_length == 현재 34)\n",
    "print(len(f.input_ids[0]))  # input_ids에서 각 턴의 최대 길이 (max_seq_length == 64)\n",
    "print(len(f.segment_ids))  # segment_ids의 턴 길이 (max_turn_length == 34)\n",
    "print(len(f.target_ids))  # target_ids의 갯수 (턴마다의 State == max_turn_length == 34)\n",
    "print(len(f.target_ids[0]))  # 각 턴마다 target의 갯수 == number of Slot Meta (== 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a3j7tb96B7r"
   },
   "source": [
    "## SUMBT 모델 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-IjCE6Db6B7r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most of code is from https://github.com/SKTBrain/SUMBT\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CosineEmbeddingLoss, CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "\n",
    "\n",
    "class BertForUtteranceEncoding(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForUtteranceEncoding, self).__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        return self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scores = None\n",
    "\n",
    "    def attention(self, q, k, v, d_k, mask=None, dropout=None):\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "#             scores = scores.masked_fill(mask == 0, -1e9)\n",
    "            scores = scores.masked_fill(mask == 0, -1e4)  # mixed precision\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            scores = dropout(scores)\n",
    "\n",
    "        self.scores = scores\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # perform linear operation and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        scores = self.attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        return output\n",
    "\n",
    "    def get_scores(self):\n",
    "        return self.scores\n",
    "\n",
    "\n",
    "class SUMBT(nn.Module):\n",
    "    def __init__(self, args, num_labels, device):  # num_labels : # of Candidate values per each Slot\n",
    "        super(SUMBT, self).__init__()\n",
    "\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.rnn_num_layers = args.num_rnn_layers\n",
    "        self.zero_init_rnn = args.zero_init_rnn\n",
    "        self.max_seq_length = args.max_seq_length\n",
    "        self.max_label_length = args.max_label_length\n",
    "        self.num_labels = num_labels\n",
    "        self.num_slots = len(num_labels)\n",
    "        self.attn_head = args.attn_head\n",
    "        self.device = device\n",
    "\n",
    "        ### Utterance Encoder\n",
    "        self.utterance_encoder = BertForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        self.bert_output_dim = self.utterance_encoder.config.hidden_size\n",
    "        self.hidden_dropout_prob = self.utterance_encoder.config.hidden_dropout_prob\n",
    "        if args.fix_utterance_encoder:\n",
    "            for p in self.utterance_encoder.bert.pooler.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        ### slot, slot-value Encoder (not trainable)\n",
    "        self.sv_encoder = BertForUtteranceEncoding.from_pretrained(\n",
    "            args.model_name_or_path\n",
    "        )\n",
    "        # os.path.join(args.bert_dir, 'bert-base-uncased.model'))\n",
    "        for p in self.sv_encoder.bert.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.slot_lookup = nn.Embedding(self.num_slots, self.bert_output_dim)\n",
    "        self.value_lookup = nn.ModuleList(\n",
    "            [nn.Embedding(num_label, self.bert_output_dim) for num_label in num_labels]\n",
    "        )\n",
    "\n",
    "        ### Attention layer\n",
    "        self.attn = MultiHeadAttention(self.attn_head, self.bert_output_dim, dropout=0)\n",
    "\n",
    "        ### RNN Belief Tracker\n",
    "        self.nbt = nn.GRU(\n",
    "            input_size=self.bert_output_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.rnn_num_layers,\n",
    "            dropout=self.hidden_dropout_prob,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.init_parameter(self.nbt)\n",
    "\n",
    "        if not self.zero_init_rnn:\n",
    "            self.rnn_init_linear = nn.Sequential(\n",
    "                nn.Linear(self.bert_output_dim, self.hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.hidden_dropout_prob),\n",
    "            )\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.bert_output_dim)\n",
    "        self.layer_norm = nn.LayerNorm(self.bert_output_dim)\n",
    "\n",
    "        ### Measure\n",
    "#         self.metric = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
    "        self.distance_metric = args.distance_metric\n",
    "        if self.distance_metric == \"cosine\":\n",
    "            self.metric = torch.nn.CosineSimilarity(dim=-1, eps=1e-08)\n",
    "        elif self.distance_metric == \"euclidean\":\n",
    "            self.metric = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
    "\n",
    "        ### Classifier\n",
    "        self.nll = CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        ### Etc.\n",
    "        self.dropout = nn.Dropout(self.hidden_dropout_prob)\n",
    "\n",
    "    def initialize_slot_value_lookup(self, label_ids, slot_ids):\n",
    "\n",
    "        self.sv_encoder.eval()\n",
    "\n",
    "        # Slot encoding\n",
    "        slot_type_ids = torch.zeros(slot_ids.size(), dtype=torch.long).to(\n",
    "            slot_ids.device\n",
    "        )\n",
    "        slot_mask = slot_ids > 0\n",
    "        hid_slot, _ = self.sv_encoder(\n",
    "            slot_ids.view(-1, self.max_label_length),\n",
    "            slot_type_ids.view(-1, self.max_label_length),\n",
    "            slot_mask.view(-1, self.max_label_length),\n",
    "        )\n",
    "        hid_slot = hid_slot[:, 0, :]\n",
    "        hid_slot = hid_slot.detach()\n",
    "        self.slot_lookup = nn.Embedding.from_pretrained(hid_slot, freeze=True)\n",
    "\n",
    "        for s, label_id in enumerate(label_ids):\n",
    "            label_type_ids = torch.zeros(label_id.size(), dtype=torch.long).to(\n",
    "                label_id.device\n",
    "            )\n",
    "            label_mask = label_id > 0\n",
    "            hid_label, _ = self.sv_encoder(\n",
    "                label_id.view(-1, self.max_label_length),\n",
    "                label_type_ids.view(-1, self.max_label_length),\n",
    "                label_mask.view(-1, self.max_label_length),\n",
    "            )\n",
    "            hid_label = hid_label[:, 0, :]\n",
    "            hid_label = hid_label.detach()\n",
    "            self.value_lookup[s] = nn.Embedding.from_pretrained(hid_label, freeze=True)\n",
    "            self.value_lookup[s].padding_idx = -1\n",
    "\n",
    "        print(\"Complete initialization of slot and value lookup\")\n",
    "        self.sv_encoder = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        token_type_ids,\n",
    "        attention_mask,\n",
    "        labels=None,\n",
    "        n_gpu=1,\n",
    "        target_slot=None,\n",
    "    ):\n",
    "        # B: Batch size, M: Max turn length, N: Max seq length, \n",
    "        # J: # of Slot Meta, H: Hidden dimension\n",
    "        \n",
    "        # input_ids: [B, M, N]\n",
    "        # token_type_ids: [B, M, N]\n",
    "        # attention_mask: [B, M, N]\n",
    "        # labels: [B, M, J]\n",
    "\n",
    "        # if target_slot is not specified, output values corresponding all slot-types\n",
    "        if target_slot is None:\n",
    "            target_slot = list(range(0, self.num_slots))\n",
    "\n",
    "        ds = input_ids.size(0)  # Batch size (B)\n",
    "        ts = input_ids.size(1)  # Max turn size (M)\n",
    "        bs = ds * ts\n",
    "        slot_dim = len(target_slot)  # J\n",
    "\n",
    "        # Utterance encoding\n",
    "        # Utterence-level로 독립적으로 인코딩하므로 flatten필요\n",
    "        hidden, _ = self.utterance_encoder(\n",
    "            input_ids.view(-1, self.max_seq_length),\n",
    "            token_type_ids.view(-1, self.max_seq_length),\n",
    "            attention_mask.view(-1, self.max_seq_length),\n",
    "        )\n",
    "        hidden = torch.mul(\n",
    "            hidden,\n",
    "            attention_mask.view(-1, self.max_seq_length, 1)\n",
    "            .expand(hidden.size())\n",
    "            .float(),\n",
    "        )\n",
    "        hidden = hidden.repeat(slot_dim, 1, 1)  # [J*M*B, N, H]\n",
    "\n",
    "        hid_slot = self.slot_lookup.weight[target_slot, :]  # Select target slot embedding\n",
    "        hid_slot = hid_slot.repeat(1, bs).view(bs * slot_dim, -1)  # [J*M*B, N, H]\n",
    "\n",
    "        # Attended utterance vector\n",
    "        hidden = self.attn(\n",
    "            hid_slot,  # q^s  [J*M*B, N, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            hidden,  # U [J*M*B, N, H]\n",
    "            mask=attention_mask.view(-1, 1, self.max_seq_length).repeat(slot_dim, 1, 1),\n",
    "        )\n",
    "        hidden = hidden.squeeze()  # h [J*M*B, H] Aggregated Slot Context\n",
    "        hidden = hidden.view(slot_dim, ds, ts, -1).view(-1, ts, self.bert_output_dim)  # [J*B, M, H]\n",
    "\n",
    "        # NBT\n",
    "        if self.zero_init_rnn:\n",
    "            h = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "        else:\n",
    "            h = hidden[:, 0, :].unsqueeze(0).repeat(self.rnn_num_layers, 1, 1)\n",
    "            h = self.rnn_init_linear(h)\n",
    "\n",
    "        if isinstance(self.nbt, nn.GRU):\n",
    "            rnn_out, _ = self.nbt(hidden, h)  # [J*B, M, H_GRU]\n",
    "        elif isinstance(self.nbt, nn.LSTM):\n",
    "            c = torch.zeros(\n",
    "                self.rnn_num_layers, input_ids.shape[0] * slot_dim, self.hidden_dim\n",
    "            ).to(\n",
    "                self.device\n",
    "            )  # [1, slot_dim*ds, hidden]\n",
    "            rnn_out, _ = self.nbt(hidden, (h, c))  # [slot_dim*ds, turn, hidden]\n",
    "        rnn_out = self.layer_norm(self.linear(self.dropout(rnn_out)))\n",
    "\n",
    "        hidden = rnn_out.view(slot_dim, ds, ts, -1)  # [J, B, M, H_GRU]\n",
    "\n",
    "        # Label (slot-value) encoding\n",
    "        loss = 0\n",
    "        loss_slot = []\n",
    "        pred_slot = []\n",
    "        output = []\n",
    "        for s, slot_id in enumerate(target_slot):  ## note: target_slots are successive\n",
    "            # loss calculation\n",
    "            hid_label = self.value_lookup[slot_id].weight\n",
    "            num_slot_labels = hid_label.size(0)\n",
    "\n",
    "            _hid_label = (\n",
    "                hid_label.unsqueeze(0)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(ds, ts, 1, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _hidden = (\n",
    "                hidden[s, :, :, :]\n",
    "                .unsqueeze(2)\n",
    "                .repeat(1, 1, num_slot_labels, 1)\n",
    "                .view(ds * ts * num_slot_labels, -1)\n",
    "            )\n",
    "            _dist = self.metric(_hid_label, _hidden).view(ds, ts, num_slot_labels)\n",
    "            if self.distance_metric == \"euclidean\":\n",
    "                _dist = -_dist\n",
    "            _, pred = torch.max(_dist, -1)  # taget_ids에서 ignore index 즉, padding일 경우 -1로 setting했었음\n",
    "            pred_slot.append(pred.view(ds, ts, 1))\n",
    "            output.append(_dist)\n",
    "\n",
    "            if labels is not None:\n",
    "                _loss = self.nll(_dist.view(ds * ts, -1), labels[:, :, s].view(-1))\n",
    "                loss_slot.append(_loss.item())\n",
    "                loss += _loss\n",
    "\n",
    "        pred_slot = torch.cat(pred_slot, 2)\n",
    "        if labels is None:\n",
    "            return output, pred_slot\n",
    "\n",
    "        # calculate joint accuracy\n",
    "        accuracy = (pred_slot == labels).view(-1, slot_dim)\n",
    "        acc_slot = (\n",
    "            torch.sum(accuracy, 0).float()\n",
    "            / torch.sum(labels.view(-1, slot_dim) > -1, 0).float()\n",
    "        )\n",
    "        acc = (\n",
    "            sum(torch.sum(accuracy, 1) / slot_dim).float()\n",
    "            / torch.sum(labels[:, :, 0].view(-1) > -1, 0).float()\n",
    "        )  # joint accuracy\n",
    "                \n",
    "        if n_gpu == 1:\n",
    "            return loss, loss_slot, acc, acc_slot, pred_slot\n",
    "        else:\n",
    "            return (\n",
    "                loss.unsqueeze(0),\n",
    "                None,\n",
    "                acc.unsqueeze(0),\n",
    "                acc_slot.unsqueeze(0),\n",
    "                pred_slot.unsqueeze(0),\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def init_parameter(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(module.weight)\n",
    "            torch.nn.init.constant_(module.bias, 0.0)\n",
    "        elif isinstance(module, nn.GRU) or isinstance(module, nn.LSTM):\n",
    "            torch.nn.init.xavier_normal_(module.weight_ih_l0)\n",
    "            torch.nn.init.xavier_normal_(module.weight_hh_l0)\n",
    "            torch.nn.init.constant_(module.bias_ih_l0, 0.0)\n",
    "            torch.nn.init.constant_(module.bias_hh_l0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYm56GEZ6B7u"
   },
   "source": [
    "## TODO-2: Ontology Pre-Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WdPyqp16B7w"
   },
   "source": [
    "Ontology의 slot type들과 이에 속하는 slot_value들을 tokenizing하는 `tokenize_ontology`를 작성하세요. <br>\n",
    "[CLS] Pooling하여 `slot_lookup` 과 `value_lookup` embedding matrix들을 초기화하는 <br>\n",
    "`initialize_slot_value_lookup`에 인자로 넘겨주세요. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zwgNUZNn6B7w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_ontology(ontology, tokenizer, max_seq_length=12):\n",
    "    slot_types = []\n",
    "    slot_values = []\n",
    "    for k, v in ontology.items():\n",
    "        tokens = tokenizer.encode(k)\n",
    "        if len(tokens) < max_seq_length:\n",
    "            gap = max_seq_length - len(tokens)\n",
    "            tokens.extend([tokenizer.pad_token_id] *  gap)\n",
    "        slot_types.append(tokens)\n",
    "        slot_value = []\n",
    "        for vv in v:\n",
    "            tokens = tokenizer.encode(vv)\n",
    "            if len(tokens) < max_seq_length:\n",
    "                gap = max_seq_length - len(tokens)\n",
    "                tokens.extend([tokenizer.pad_token_id] *  gap)\n",
    "            slot_value.append(tokens)\n",
    "        slot_values.append(torch.LongTensor(slot_value))\n",
    "    return torch.LongTensor(slot_types), slot_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "attmAW3A6B7w",
    "outputId": "9dbf4e3d-f077-4782-9d3b-d7c8c00159ff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4, 4, 103, 13, 4, 7, 5, 4, 4, 4, 12, 12, 9, 67, 4, 4, 7, 4, 7, 4, 4, 5, 4, 4, 12, 1442, 9, 44, 4, 10, 4, 4, 7, 4, 266, 1442, 266, 1442, 298, 5, 1442, 286]\n",
      "Tokenized Slot:  torch.Size([45, 12])\n",
      "Tokenized Value of 관광-경치 좋은 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-교육적 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-문화 예술 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-역사적 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-이름 torch.Size([103, 12])\n",
      "Tokenized Value of 관광-종류 torch.Size([13, 12])\n",
      "Tokenized Value of 관광-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 관광-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-가격대 torch.Size([5, 12])\n",
      "Tokenized Value of 숙소-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-수영장 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-스파 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-예약 기간 torch.Size([12, 12])\n",
      "Tokenized Value of 숙소-예약 명수 torch.Size([12, 12])\n",
      "Tokenized Value of 숙소-예약 요일 torch.Size([9, 12])\n",
      "Tokenized Value of 숙소-이름 torch.Size([67, 12])\n",
      "Tokenized Value of 숙소-인터넷 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-조식 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-종류 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 숙소-헬스장 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 숙소-흡연 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-가격대 torch.Size([5, 12])\n",
      "Tokenized Value of 식당-도보 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-야외석 유무 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-예약 명수 torch.Size([12, 12])\n",
      "Tokenized Value of 식당-예약 시간 torch.Size([1442, 12])\n",
      "Tokenized Value of 식당-예약 요일 torch.Size([9, 12])\n",
      "Tokenized Value of 식당-이름 torch.Size([44, 12])\n",
      "Tokenized Value of 식당-인터넷 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-종류 torch.Size([10, 12])\n",
      "Tokenized Value of 식당-주류 판매 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-주차 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 식당-지역 torch.Size([7, 12])\n",
      "Tokenized Value of 식당-흡연 가능 torch.Size([4, 12])\n",
      "Tokenized Value of 지하철-도착지 torch.Size([266, 12])\n",
      "Tokenized Value of 지하철-출발 시간 torch.Size([1442, 12])\n",
      "Tokenized Value of 지하철-출발지 torch.Size([266, 12])\n",
      "Tokenized Value of 택시-도착 시간 torch.Size([1442, 12])\n",
      "Tokenized Value of 택시-도착지 torch.Size([298, 12])\n",
      "Tokenized Value of 택시-종류 torch.Size([5, 12])\n",
      "Tokenized Value of 택시-출발 시간 torch.Size([1442, 12])\n",
      "Tokenized Value of 택시-출발지 torch.Size([286, 12])\n"
     ]
    }
   ],
   "source": [
    "slot_type_ids, slot_values_ids = tokenize_ontology(ontology, tokenizer, 12)\n",
    "num_labels = [len(s) for s in slot_values_ids]  # 각 Slot 별 후보 Values의 갯수\n",
    "print(num_labels)\n",
    "print(\"Tokenized Slot: \", slot_type_ids.size())\n",
    "for slot, slot_value_id in zip(slot_meta, slot_values_ids):\n",
    "    print(f\"Tokenized Value of {slot}\", slot_value_id.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCsCGN0f6B7x"
   },
   "source": [
    "## Model 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aQSRYG6e6B7x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# argsparse 있던 위치\n",
    "\n",
    "num_labels = [len(s) for s in slot_values_ids]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = 1 if torch.cuda.device_count() < 2 else torch.cuda.device_count()\n",
    "n_epochs = args.num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NZNUF9k86B7x",
    "outputId": "4ef347fd-6fa1-4f26-e8a4-8133614f9380",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertForUtteranceEncoding: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForUtteranceEncoding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete initialization of slot and value lookup\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f79dee3a6d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SUMBT(args, num_labels, device)\n",
    "model.initialize_slot_value_lookup(slot_values_ids, slot_type_ids)  # Tokenized Ontology의 Pre-encoding using BERT_SV\n",
    "model.to(device)\n",
    "\n",
    "wandb.watch(model)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulJJGp5a6B7x"
   },
   "source": [
    "## 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yBU7KP5A6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data_utils import WOSDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, sampler=train_sampler, collate_fn=processor.collate_fn)\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, batch_size=8, sampler=dev_sampler, collate_fn=processor.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVQC_XUG6B7y"
   },
   "source": [
    "## Optimizer & Scheduler 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wK-LWnHU6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(t_total * args.warmup_ratio), num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-f0L44h6B7y"
   },
   "source": [
    "## TODO-3: Inference code 작성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jCGuenx36B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluation import _evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LBXWTFHi6B7y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, eval_loader, processor, device):\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    for batch in eval_loader:\n",
    "        input_ids, segment_ids, input_masks, target_ids, num_turns, guids = \\\n",
    "        [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, pred_slot = model(\n",
    "                input_ids, segment_ids, input_masks, labels=None, n_gpu=1\n",
    "            )\n",
    "        \n",
    "        batch_size = input_ids.size(0)\n",
    "        for i in range(batch_size):\n",
    "            guid = guids[i]\n",
    "            states = processor.recover_state(pred_slot.tolist()[i], num_turns[i])\n",
    "            for tid, state in enumerate(states):\n",
    "                predictions[f\"{guid}-{tid}\"] = state\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW-qyUd_6B7y"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('20epoch.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7tpx4426B7z",
    "outputId": "9538d5cc-c271-4176-e1a1-af2d1121c40c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:21,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [0/788] 104.410637\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:56<06:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [100/788] 37.540020\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:52<05:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [200/788] 44.816124\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:48<04:34,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [300/788] 40.122162\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:44<03:36,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [400/788] 29.841877\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:40<02:40,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [500/788] 22.619574\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:36<01:45,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [600/788] 24.627533\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:32<00:49,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25] [700/788] 24.519239\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:21<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.024236453201970442, 'turn_slot_accuracy': 0.8599321291735084, 'turn_slot_f1': 0.27711689478673746}\n",
      "new best JGA score!  0.024236453201970442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.024236453201970442\n",
      "turn_slot_accuracy: 0.8599321291735084\n",
      "turn_slot_f1: 0.27711689478673746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:25,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [0/788] 19.621624\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:57<06:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [100/788] 18.740559\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:54<05:32,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [200/788] 22.828310\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:50<04:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [300/788] 21.163799\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:47<03:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [400/788] 19.385239\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:43<02:41,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [500/788] 15.632195\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:40<01:45,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [600/788] 15.732591\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:36<00:49,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25] [700/788] 13.314215\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:25<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.2147783251231527, 'turn_slot_accuracy': 0.9532085385878625, 'turn_slot_f1': 0.7915122588019}\n",
      "new best JGA score!  0.2147783251231527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.2147783251231527\n",
      "turn_slot_accuracy: 0.9532085385878625\n",
      "turn_slot_f1: 0.7915122588019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [0/788] 11.541057\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:57<06:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [100/788] 11.144128\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:53<05:31,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [200/788] 11.644760\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:50<04:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [300/788] 8.692095\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:46<03:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [400/788] 8.016251\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:43<02:41,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [500/788] 7.030541\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:39<01:45,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [600/788] 7.558396\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:35<00:49,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25] [700/788] 4.258655\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:24<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.5387192118226601, 'turn_slot_accuracy': 0.9820470717022528, 'turn_slot_f1': 0.9229129661990364}\n",
      "new best JGA score!  0.5387192118226601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.5387192118226601\n",
      "turn_slot_accuracy: 0.9820470717022528\n",
      "turn_slot_f1: 0.9229129661990364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [0/788] 4.926631\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:57<06:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [100/788] 5.472364\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:53<05:31,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [200/788] 4.380117\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:50<04:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [300/788] 2.616208\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:46<03:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [400/788] 2.813258\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:43<02:43,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [500/788] 2.637840\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:39<01:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [600/788] 2.305617\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:35<00:49,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25] [700/788] 2.999552\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:24<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7077832512315271, 'turn_slot_accuracy': 0.990274767378223, 'turn_slot_f1': 0.962375878892187}\n",
      "new best JGA score!  0.7077832512315271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.7077832512315271\n",
      "turn_slot_accuracy: 0.990274767378223\n",
      "turn_slot_f1: 0.962375878892187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:21,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [0/788] 3.240969\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:58<06:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [100/788] 4.397139\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:53<05:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [200/788] 3.156816\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:49<04:30,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [300/788] 2.455577\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:45<03:35,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [400/788] 4.219334\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:40<02:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [500/788] 2.937212\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:36<01:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [600/788] 3.964071\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:32<00:48,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25] [700/788] 2.014356\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:20<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7601970443349754, 'turn_slot_accuracy': 0.991899288451019, 'turn_slot_f1': 0.9686214228611153}\n",
      "new best JGA score!  0.7601970443349754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.7601970443349754\n",
      "turn_slot_accuracy: 0.991899288451019\n",
      "turn_slot_f1: 0.9686214228611153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:19,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [0/788] 1.623150\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:56<06:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [100/788] 2.934499\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:52<05:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [200/788] 2.684128\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:48<04:31,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [300/788] 2.603491\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:43<03:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [400/788] 2.154005\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:39<02:40,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [500/788] 2.326418\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:35<01:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [600/788] 1.830697\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:31<00:48,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25] [700/788] 2.456482\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:19<00:00,  1.79it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7519211822660099, 'turn_slot_accuracy': 0.9918730158730256, 'turn_slot_f1': 0.968917896551551}\n",
      "joint_goal_accuracy: 0.7519211822660099\n",
      "turn_slot_accuracy: 0.9918730158730256\n",
      "turn_slot_f1: 0.968917896551551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [0/788] 1.644053\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:56<06:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [100/788] 1.697249\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:52<05:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [200/788] 1.154502\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:47<04:30,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [300/788] 2.724419\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:43<03:35,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [400/788] 1.453510\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:39<02:40,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [500/788] 1.521796\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:34<01:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [600/788] 2.991313\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:30<00:48,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25] [700/788] 1.257531\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:19<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7773399014778325, 'turn_slot_accuracy': 0.9930377668308757, 'turn_slot_f1': 0.9731870051172208}\n",
      "new best JGA score!  0.7773399014778325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.7773399014778325\n",
      "turn_slot_accuracy: 0.9930377668308757\n",
      "turn_slot_f1: 0.9731870051172208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:17,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [0/788] 1.510041\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:56<06:22,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [100/788] 2.424684\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:51<05:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [200/788] 1.518199\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:47<04:30,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [300/788] 2.330397\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:43<03:35,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [400/788] 2.097480\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:38<02:40,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [500/788] 0.990614\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:34<01:44,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [600/788] 0.884854\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:30<00:48,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25] [700/788] 1.598377\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:18<00:00,  1.80it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7704433497536946, 'turn_slot_accuracy': 0.9930640394088728, 'turn_slot_f1': 0.973327998816286}\n",
      "joint_goal_accuracy: 0.7704433497536946\n",
      "turn_slot_accuracy: 0.9930640394088728\n",
      "turn_slot_f1: 0.973327998816286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [0/788] 1.592355\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:56<06:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [100/788] 1.178182\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:52<05:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [200/788] 1.589411\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:47<04:32,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [300/788] 1.260870\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:43<03:35,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [400/788] 2.550734\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:39<02:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [500/788] 1.623556\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:35<01:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [600/788] 2.143356\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:30<00:48,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25] [700/788] 0.982415\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:19<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7824630541871921, 'turn_slot_accuracy': 0.9934362342638271, 'turn_slot_f1': 0.9744343564618673}\n",
      "new best JGA score!  0.7824630541871921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.7824630541871921\n",
      "turn_slot_accuracy: 0.9934362342638271\n",
      "turn_slot_f1: 0.9744343564618673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:19,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [0/788] 1.118413\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:56<06:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [100/788] 1.013630\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:54<05:31,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [200/788] 0.986930\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:51<04:35,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [300/788] 1.246149\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:47<03:39,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [400/788] 1.521439\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:44<02:42,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [500/788] 1.547518\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:44<01:46,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [600/788] 0.913875\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:40<00:49,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25] [700/788] 1.029707\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:29<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7976354679802956, 'turn_slot_accuracy': 0.9938960043787711, 'turn_slot_f1': 0.9762303037375788}\n",
      "new best JGA score!  0.7976354679802956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.7976354679802956\n",
      "turn_slot_accuracy: 0.9938960043787711\n",
      "turn_slot_f1: 0.9762303037375788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [0/788] 1.134444\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:58<06:42,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [100/788] 0.931127\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:54<05:31,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [200/788] 0.921023\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:50<04:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [300/788] 1.357408\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:47<03:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [400/788] 0.986587\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:44<02:42,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [500/788] 1.400148\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:40<01:45,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [600/788] 0.367236\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:36<00:48,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25] [700/788] 0.872630\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:25<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.8051231527093596, 'turn_slot_accuracy': 0.9940054734537556, 'turn_slot_f1': 0.9779937320732018}\n",
      "new best JGA score!  0.8051231527093596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.8051231527093596\n",
      "turn_slot_accuracy: 0.9940054734537556\n",
      "turn_slot_f1: 0.9779937320732018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:26,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [0/788] 1.568519\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:57<06:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [100/788] 0.612941\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:53<05:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [200/788] 0.598613\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:49<04:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [300/788] 0.593927\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:46<03:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [400/788] 0.770777\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:43<02:41,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [500/788] 0.745060\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:39<01:45,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [600/788] 1.527380\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:36<00:49,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25] [700/788] 1.019946\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:25<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.8063054187192118, 'turn_slot_accuracy': 0.9940667761357485, 'turn_slot_f1': 0.9774093814967211}\n",
      "new best JGA score!  0.8063054187192118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_goal_accuracy: 0.8063054187192118\n",
      "turn_slot_accuracy: 0.9940667761357485\n",
      "turn_slot_f1: 0.9774093814967211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [0/788] 0.659234\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:57<06:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [100/788] 0.466948\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:53<05:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [200/788] 0.539253\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:49<04:33,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [300/788] 0.829501\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:45<03:37,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [400/788] 0.403928\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:42<02:41,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [500/788] 1.065463\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:38<01:45,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [600/788] 1.164370\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 701/788 [06:35<00:49,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25] [700/788] 1.949641\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [07:24<00:00,  1.77it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.8017733990147783, 'turn_slot_accuracy': 0.9939178981937656, 'turn_slot_f1': 0.9760614657391521}\n",
      "joint_goal_accuracy: 0.8017733990147783\n",
      "turn_slot_accuracy: 0.9939178981937656\n",
      "turn_slot_f1: 0.9760614657391521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/788 [00:00<07:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25] [0/788] 0.698500\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/788 [00:57<06:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25] [100/788] 0.362703\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 201/788 [01:54<05:35,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25] [200/788] 0.722313\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/788 [02:50<04:34,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25] [300/788] 0.433381\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/788 [03:47<03:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25] [400/788] 0.510744\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 501/788 [04:43<02:42,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25] [500/788] 0.760836\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 601/788 [05:40<01:48,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25] [600/788] 0.499246\n",
      "inferencing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 636/788 [06:00<01:25,  1.77it/s]"
     ]
    }
   ],
   "source": [
    "# for checkpoint management\n",
    "chk_list = []\n",
    "output_dir = increment_output_dir(wandb.run.name)\n",
    "\n",
    "if not os.path.exists(f\"checkpoint/{output_dir}\"):\n",
    "    os.makedirs(f\"checkpoint/{output_dir}\")       \n",
    "\n",
    "\n",
    "best_score, best_checkpoint = 0, 0\n",
    "epoch_miss_labels = defaultdict(list)\n",
    "for epoch in range(n_epochs):\n",
    "    batch_loss = []\n",
    "    batch_loss_per_100step = []\n",
    "    for step, batch in enumerate(tqdm(train_loader)):\n",
    "        model.train()\n",
    "        input_ids, segment_ids, input_masks, target_ids, num_turns, guids  = \\\n",
    "        [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "\n",
    "        with amp.autocast():\n",
    "            # Forwabatch_size        \n",
    "            if n_gpu == 1:\n",
    "                loss, loss_slot, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "            else:\n",
    "                loss, _, acc, acc_slot, _ = model(input_ids, segment_ids, input_masks, target_ids, n_gpu)\n",
    "\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "#         if step % 100 == 0 or step == len(train_loader):\n",
    "        if step % 100 == 0:\n",
    "#             batch_loss_per_100step.append(loss.item())\n",
    "            print('[%d/%d] [%d/%d] %f' % (epoch+1, n_epochs, step, len(train_loader), loss.item()))\n",
    "#             # epoch를 마쳤거나, 최저 loss 갱신했을 때 추론\n",
    "#             if step == len(train_loader) or min(batch_loss_per_100step) >= loss.item():\n",
    "            print('inferencing')\n",
    "    predictions = inference(model, dev_loader, processor, device)\n",
    "#             eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "    eval_result, batch_miss_labels = _evaluation(predictions, dev_labels, slot_meta)\n",
    "    if epoch >= 5:\n",
    "        epoch_miss_labels[epoch].extend(batch_miss_labels)   \n",
    "\n",
    "    current_score = eval_result['joint_goal_accuracy']\n",
    "\n",
    "    if best_score < current_score:\n",
    "        best_score = current_score\n",
    "        print('new best JGA score! ', best_score)\n",
    "\n",
    "        # checkpoint 수 관리\n",
    "        if len(chk_list) >= 1:\n",
    "            os.remove(chk_list.pop(0))\n",
    "\n",
    "        output_path = f\"checkpoint/{output_dir}/{epoch}_{step}_{best_score}.pth\"\n",
    "        chk_list.append(output_path)\n",
    "\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, output_path)\n",
    "    for k, v in eval_result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    wandb.log({\n",
    "        \"loss\": loss.item(),\n",
    "        \"Joint Goal Accuracy\": eval_result['joint_goal_accuracy'],\n",
    "        \"Turn Slot_Accuracy\": eval_result['turn_slot_accuracy'],\n",
    "        \"Turn Slot F1\": eval_result['turn_slot_f1']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_miss_labels\n",
    "\n",
    "with open('miss_labels.json', 'w') as outfile:\n",
    "    json.dump(epoch_miss_labels, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model1 = SUMBT(args, num_labels, device)\n",
    "# model1.initialize_slot_value_lookup(slot_values_ids, slot_type_ids)  # Tokenized Ontology의 Pre-encoding using BERT_SV\n",
    "# model1.to(device)\n",
    "\n",
    "\n",
    "# no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "# optimizer_grouped_parameters = [\n",
    "#         {\n",
    "#             \"params\": [p for n, p in model1.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#             \"weight_decay\": args.weight_decay,\n",
    "#         },\n",
    "#         {\n",
    "#             \"params\": [p for n, p in model1.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#             \"weight_decay\": 0.0,\n",
    "#         },\n",
    "#     ]\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=1e-8)\n",
    "\n",
    "# PATH = 'checkpoint/laced-lake-76/23_100_0.8232512315270936.pth'\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model1.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# # model1.load_state_dict(torch.load('checkpoint/solar-sweep-3/9_700_0.7885714285714286.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHUyY11B6B70"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzusVESG6B70",
    "outputId": "972f9d9f-336e-452d-c535-0aef4638f40f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/repo/taepd/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=True, dialogue_level=True\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "88F6j_5v6B71",
    "outputId": "9fdd691f-2974-47d4-f71c-fd454048f9eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1-IQhzx16B71"
   },
   "outputs": [],
   "source": [
    "json.dump(predictions, open('predictions.csv', 'w'), indent=2, ensure_ascii=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SUMBT.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
