{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ba2d1-420f-4ff5-970e-c4d5099b1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install prettyprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93d861-fb82-403d-9e51-0dc603485801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install ruamel.yaml  # 안되면 conda install raumel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab8be6b-35b0-47d8-b3b6-da36e430e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb758a5a",
   "metadata": {
    "id": "eb758a5a"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "# # 이상 검출을 위한 코드\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "from transformers import (BertTokenizer, \n",
    "                          BertModel,  \n",
    "                          BertConfig,\n",
    "                          AdamW, \n",
    "                          get_linear_schedule_with_warmup\n",
    "                          )\n",
    "from transformers.modeling_bert import BertOnlyMLMHead\n",
    "\n",
    "\n",
    "\n",
    "from data_utils import (load_dataset, \n",
    "                        get_examples_from_dialogues, \n",
    "                        convert_state_dict, \n",
    "                        DSTInputExample, \n",
    "                        OpenVocabDSTFeature, \n",
    "                        DSTPreprocessor, \n",
    "                        WOSDataset,\n",
    "                        custom_to_mask, \n",
    "                        custom_get_examples_from_dialogues,\n",
    "                        set_seed, \n",
    "                        YamlConfigManager,\n",
    "                        )\n",
    "\n",
    "from inference import inference\n",
    "from evaluation import _evaluation\n",
    "from model import TRADE, masked_cross_entropy_for_value\n",
    "from preprocessor import TRADEPreprocessor\n",
    "\n",
    "from prettyprinter import cpprint\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c932e0a-719a-432a-95ba-3cfe21d029f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name : cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device Name : {device}')\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b552a097-f5db-4537-a1e7-bd2c3e9e013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_output_dir(output_path, exist_ok=False):\n",
    "  path = Path(output_path)\n",
    "  if (path.exists() and exist_ok) or (not path.exists()):\n",
    "    return str(path)\n",
    "  else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" %path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d81bb2-713f-468f-91ff-e1b467d46395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easydict.EasyDict({\n",
      "    'data_dir': '../input/data/train_dataset',\n",
      "    'model_dir': 'results',\n",
      "    'train_batch_size': 4,\n",
      "    'eval_batch_size': 8,\n",
      "    'learning_rate': 3e-05,\n",
      "    'adam_epsilon': 1e-08,\n",
      "    'max_grad_norm': 1.0,\n",
      "    'num_train_epochs': 30,\n",
      "    'warmup_ratio': 0.0,\n",
      "    'random_seed': 42,\n",
      "    'n_gate': 5,\n",
      "    'teacher_forcing_ratio': 0.5,\n",
      "    'model_name_or_path': 'dsksd/bert-ko-small-minimal',\n",
      "    'proj_dim': 'None',\n",
      "    'tag': ['trade'],\n",
      "    'use_kfold': False,\n",
      "    'num_k': 0,\n",
      "    'val_ratio': 0.1,\n",
      "    'scheduler': 'Linear',\n",
      "    'mask': True\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "cfg = YamlConfigManager('../config.yml', 'base').values\n",
    "cpprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a10928f-29a2-4ba6-a628-fe549affce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# !wandb login  # run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ededbd-7bb0-462c-8cd6-db98c65fcc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaepd\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">firm-monkey-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/taepd/DST\" target=\"_blank\">https://wandb.ai/taepd/DST</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/taepd/DST/runs/dkkj8osa\" target=\"_blank\">https://wandb.ai/taepd/DST/runs/dkkj8osa</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/repo/taepd/code/notebooks/wandb/run-20210518_114444-dkkj8osa</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --wandb initialize with configuration\n",
    "# wandb.init(project=\"TRADE\")\n",
    "wandb.init(project='DST', tags=cfg.tag, config=cfg)\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb47174-490c-44fa-a544-dd2c33b4108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current learning rate\n",
    "def get_lr(scheduler):\n",
    "    return scheduler.get_last_lr()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc29014",
   "metadata": {
    "id": "1dc29014",
    "outputId": "d08adfe1-de56-4c74-f44f-336d972a14fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 6538.49it/s] \n",
      "100%|██████████| 699/699 [00:00<00:00, 10622.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# random seed 고정\n",
    "set_seed(cfg.random_seed)\n",
    "\n",
    "# Data Loading\n",
    "train_data_file = \"/opt/ml/repo/taepd/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file, cfg.val_ratio)\n",
    "\n",
    "# dialogue_level=False : SUMBT와 다르게 dialogue context level로 input하므로\n",
    "# train_examples = get_examples_from_dialogues(train_data,\n",
    "#                                              user_first=False,\n",
    "#                                              dialogue_level=False)\n",
    "# dev_examples = get_examples_from_dialogues(dev_data,\n",
    "#                                            user_first=False,\n",
    "#                                            dialogue_level=False)\n",
    "train_examples = custom_get_examples_from_dialogues(\n",
    "    train_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "dev_examples = custom_get_examples_from_dialogues(\n",
    "    dev_data, user_first=False, dialogue_level=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cddce0f",
   "metadata": {
    "id": "3cddce0f",
    "outputId": "d7bf48e6-3f20-4688-dad6-572b818950aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46170\n",
      "5075\n"
     ]
    }
   ],
   "source": [
    "print(len(train_examples))\n",
    "print(len(dev_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5397e36b-d495-4b98-b739-d1e01436b543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSTInputExample(guid='snowy-hat-8324:관광_식당_11-0', context_turns=[], current_turn=['', ' # ', '서울 중앙에 있는 박물관을 찾아주세요', ' * '], label=['관광-종류-박물관', '관광-지역-서울 중앙'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee874d10",
   "metadata": {
    "id": "ee874d10"
   },
   "source": [
    "## TRADE Preprocessor\n",
    "\n",
    "BERT Encoder가 적용된 TRADE의 preprocessor입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3af720",
   "metadata": {
    "id": "6a3af720",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class TRADEPreprocessor(DSTPreprocessor):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         slot_meta,\n",
    "#         src_tokenizer,\n",
    "#         trg_tokenizer=None,\n",
    "#         ontology=None,\n",
    "#         max_seq_length=512,\n",
    "#     ):\n",
    "#         self.slot_meta = slot_meta\n",
    "#         self.src_tokenizer = src_tokenizer\n",
    "#         self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "#         self.ontology = ontology\n",
    "#         self.gating2id = {\"none\": 0, \"dontcare\": 1, \"yes\": 2, \"no\": 3, \"ptr\": 4}\n",
    "#         self.id2gating = {v: k for k, v in self.gating2id.items()}\n",
    "#         self.max_seq_length = max_seq_length\n",
    "\n",
    "#     def _convert_example_to_feature(self, example):\n",
    "#         dialogue_context = \" [SEP] \".join(example.context_turns + example.current_turn)\n",
    "\n",
    "#         input_id = self.src_tokenizer.encode(dialogue_context, add_special_tokens=False)\n",
    "#         max_length = self.max_seq_length - 2\n",
    "#         if len(input_id) > max_length:\n",
    "#             gap = len(input_id) - max_length\n",
    "#             input_id = input_id[gap:]\n",
    "\n",
    "#         input_id = (\n",
    "#             [self.src_tokenizer.cls_token_id]\n",
    "#             + input_id\n",
    "#             + [self.src_tokenizer.sep_token_id]\n",
    "#         )\n",
    "#         segment_id = [0] * len(input_id)\n",
    "\n",
    "#         target_ids = []\n",
    "#         gating_id = []\n",
    "#         if not example.label:\n",
    "#             example.label = []\n",
    "\n",
    "#         state = convert_state_dict(example.label)\n",
    "#         for slot in self.slot_meta:\n",
    "#             value = state.get(slot, \"none\")\n",
    "#             target_id = self.trg_tokenizer.encode(value, add_special_tokens=False) + [\n",
    "#                 self.trg_tokenizer.sep_token_id\n",
    "#             ]\n",
    "#             target_ids.append(target_id)\n",
    "#             gating_id.append(self.gating2id.get(value, self.gating2id[\"ptr\"]))\n",
    "#         target_ids = self.pad_ids(target_ids, self.trg_tokenizer.pad_token_id)\n",
    "#         return OpenVocabDSTFeature(\n",
    "#             example.guid, input_id, segment_id, gating_id, target_ids\n",
    "#         )\n",
    "\n",
    "#     def convert_examples_to_features(self, examples):\n",
    "#         return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "#     def recover_state(self, gate_list, gen_list):\n",
    "#         assert len(gate_list) == len(self.slot_meta)\n",
    "#         assert len(gen_list) == len(self.slot_meta)\n",
    "\n",
    "#         recovered = []\n",
    "#         for slot, gate, value in zip(self.slot_meta, gate_list, gen_list):\n",
    "#             if self.id2gating[gate] == \"none\":\n",
    "#                 continue\n",
    "\n",
    "#             if self.id2gating[gate] in [\"dontcare\", \"yes\", \"no\"]:\n",
    "#                 recovered.append(\"%s-%s\" % (slot, self.id2gating[gate]))\n",
    "#                 continue\n",
    "\n",
    "#             token_id_list = []\n",
    "#             for id_ in value:\n",
    "#                 if id_ in self.trg_tokenizer.all_special_ids:\n",
    "#                     break\n",
    "\n",
    "#                 token_id_list.append(id_)\n",
    "#             value = self.trg_tokenizer.decode(token_id_list, skip_special_tokens=True)\n",
    "\n",
    "#             if value == \"none\":\n",
    "#                 continue\n",
    "\n",
    "#             recovered.append(\"%s-%s\" % (slot, value))\n",
    "#         return recovered\n",
    "\n",
    "#     def collate_fn(self, batch):\n",
    "#         guids = [b.guid for b in batch]\n",
    "#         input_ids = torch.LongTensor(\n",
    "#             self.pad_ids([b.input_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "#         )\n",
    "#         segment_ids = torch.LongTensor(\n",
    "#             self.pad_ids([b.segment_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "#         )\n",
    "#         input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "\n",
    "#         gating_ids = torch.LongTensor([b.gating_id for b in batch])\n",
    "#         target_ids = self.pad_id_of_matrix(\n",
    "#             [torch.LongTensor(b.target_ids) for b in batch],\n",
    "#             self.trg_tokenizer.pad_token_id,\n",
    "#         )\n",
    "#         return input_ids, segment_ids, input_masks, gating_ids, target_ids, guids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d083031",
   "metadata": {
    "id": "1d083031"
   },
   "source": [
    "## Convert_Examples_to_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a534ee7",
   "metadata": {
    "id": "9a534ee7",
    "outputId": "986287a8-eed6-47e7-fb82-79a272e59914",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "# processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512)\n",
    "\n",
    "# train_features = processor.convert_examples_to_features(train_examples)\n",
    "# dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc96f165-a1c4-4504-baf0-70f1f01aae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessor\n",
    "tokenizer = BertTokenizer.from_pretrained(cfg.model_name_or_path)\n",
    "\n",
    "# Dealing with long texts The maximum sequence length of BERT is 512.\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512, n_gate=cfg.n_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d2573a-e4f6-4c38-afa8-52ded56b4f86",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Extracting Features...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2e9f6b6ef0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # Extracting Featrues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting Features...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_custom_convert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdev_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_custom_convert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/taepd/code/preprocessor.py\u001b[0m in \u001b[0;36msep_custom_convert_examples_to_features\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msep_custom_convert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sep_custom_convert_example_to_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/taepd/code/preprocessor.py\u001b[0m in \u001b[0;36m_sep_custom_convert_example_to_feature\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mslot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslot_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             target_id = self.trg_tokenizer.encode(value, add_special_tokens=False) + [\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1981\u001b[0m         )\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2303\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2305\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2306\u001b[0m         )\n\u001b[1;32m   2307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   2752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m         batch_outputs = BatchEncoding(\n\u001b[0;32m-> 2754\u001b[0;31m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2755\u001b[0m         )\n\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     ):\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncodingFast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/_collections_abc.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keys\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # # Extracting Featrues\n",
    "# cpprint('Extracting Features...')\n",
    "# train_features = processor.sep_custom_convert_examples_to_features(train_examples)\n",
    "# dev_features = processor.sep_custom_convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f5519d-4da7-403e-8dda-ce9db418ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 train data InputFeatur 저장\n",
    "# with open('custom_train_features.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_features, f)\n",
    "# with open('custom_dev_features.pickle', 'wb') as f:\n",
    "#     pickle.dump(dev_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "410d9424-495a-4ea0-ab6d-6b78313ed0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 파일 사용\n",
    "with open('custom_train_features.pickle', 'rb') as f:\n",
    "    train_features = pickle.load(f)\n",
    "with open('custom_dev_features.pickle', 'rb') as f:\n",
    "    dev_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12fe89e6",
   "metadata": {
    "id": "12fe89e6",
    "outputId": "04cd16ee-428b-4ca2-ed05-e341582028fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46170\n",
      "5075\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e09aa88",
   "metadata": {
    "id": "6e09aa88"
   },
   "source": [
    "# TRADE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba9a4a",
   "metadata": {
    "id": "4eba9a4a"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb123f9",
   "metadata": {
    "id": "3cb123f9"
   },
   "outputs": [],
   "source": [
    "class TRADE(nn.Module):\n",
    "    def __init__(self, config, slot_vocab, slot_meta, pad_idx=0):\n",
    "        super(TRADE, self).__init__()\n",
    "        self.config = config\n",
    "        self.slot_meta = slot_meta\n",
    "        if config.model_name_or_path:\n",
    "            self.encoder = BertModel.from_pretrained(config.model_name_or_path)\n",
    "        else:\n",
    "            self.encoder = BertModel(config)\n",
    "            \n",
    "        self.decoder = SlotGenerator(\n",
    "            config.vocab_size,\n",
    "            config.hidden_size,\n",
    "            config.hidden_dropout_prob,\n",
    "            config.n_gate,\n",
    "            None,\n",
    "            pad_idx,\n",
    "        )\n",
    "        \n",
    "        self.decoder.set_slot_idx(slot_vocab)\n",
    "        \n",
    "        self.mlm_head = BertOnlyMLMHead(config)\n",
    "        self.tie_weight()\n",
    "\n",
    "    def tie_weight(self):\n",
    "        self.decoder.embed.weight = self.encoder.embeddings.word_embeddings.weight\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask=None, max_len=10, teacher=None):\n",
    "\n",
    "        encoder_outputs, pooled_output = self.encoder(input_ids=input_ids)\n",
    "        all_point_outputs, all_gate_outputs = self.decoder(\n",
    "            input_ids, encoder_outputs, pooled_output.unsqueeze(0), attention_mask, max_len, teacher\n",
    "        )\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def mask_tokens(inputs, tokenizer, config, mlm_probability=0.15):\n",
    "        \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
    "        labels = inputs.clone()\n",
    "        # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
    "        probability_matrix = torch.full(labels.shape, mlm_probability).to(device)\n",
    "        #special_tokens_mask = [tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()]\n",
    "\n",
    "        probability_matrix.masked_fill_(torch.eq(labels, 0), value=0.0)\n",
    "\n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).to(device=device, dtype=torch.bool) & masked_indices\n",
    "        inputs[indices_replaced] = tokenizer.convert_tokens_to_ids([\"[MASK]\"])[0]\n",
    "\n",
    "        # 10% of the time, we replace masked input tokens with random word\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).to(device=device, dtype=torch.bool) & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(config.vocab_size, labels.shape, device=device, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random].to(device)\n",
    "\n",
    "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "        return inputs, labels\n",
    "    \n",
    "    def forward_pretrain(self, input_ids, tokenizer):\n",
    "        input_ids, labels = self.mask_tokens(input_ids, tokenizer, self.config)\n",
    "        encoder_outputs, _ = self.encoder(input_ids=input_ids)\n",
    "        mlm_logits = self.mlm_head(encoder_outputs)\n",
    "        \n",
    "        return mlm_logits, labels\n",
    "    \n",
    "class SlotGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, hidden_size, dropout, n_gate, proj_dim=None, pad_idx=0\n",
    "    ):\n",
    "        super(SlotGenerator, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = nn.Embedding(\n",
    "            vocab_size, hidden_size, padding_idx=pad_idx\n",
    "        )  # shared with encoder\n",
    "\n",
    "        if proj_dim:\n",
    "            self.proj_layer = nn.Linear(hidden_size, proj_dim, bias=False)\n",
    "        else:\n",
    "            self.proj_layer = None\n",
    "        self.hidden_size = proj_dim if proj_dim else hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            self.hidden_size, self.hidden_size, 1, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.n_gate = n_gate\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_gen = nn.Linear(self.hidden_size * 3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.w_gate = nn.Linear(self.hidden_size, n_gate)\n",
    "\n",
    "    def set_slot_idx(self, slot_vocab_idx):\n",
    "        whole = []\n",
    "        max_length = max(map(len, slot_vocab_idx))\n",
    "        for idx in slot_vocab_idx:\n",
    "            if len(idx) < max_length:\n",
    "                gap = max_length - len(idx)\n",
    "                idx.extend([self.pad_idx] * gap)\n",
    "            whole.append(idx)\n",
    "        self.slot_embed_idx = whole  # torch.LongTensor(whole)\n",
    "\n",
    "    def embedding(self, x):\n",
    "        x = self.embed(x)\n",
    "        if self.proj_layer:\n",
    "            x = self.proj_layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, encoder_output, hidden, input_masks, max_len, teacher=None\n",
    "    ):\n",
    "        input_masks = input_masks.ne(1)\n",
    "        # J, slot_meta : key : [domain, slot] ex> LongTensor([1,2])\n",
    "        # J,2\n",
    "        batch_size = encoder_output.size(0)\n",
    "        slot = torch.LongTensor(self.slot_embed_idx).to(input_ids.device)  ##\n",
    "        slot_e = torch.sum(self.embedding(slot), 1)  # J,d\n",
    "        J = slot_e.size(0)\n",
    "\n",
    "        all_point_outputs = torch.zeros(batch_size, J, max_len, self.vocab_size).to(\n",
    "            input_ids.device\n",
    "        )\n",
    "        \n",
    "        # Parallel Decoding\n",
    "        w = slot_e.repeat(batch_size, 1).unsqueeze(1)\n",
    "        hidden = hidden.repeat_interleave(J, dim=1)\n",
    "        encoder_output = encoder_output.repeat_interleave(J, dim=0)\n",
    "        input_ids = input_ids.repeat_interleave(J, dim=0)\n",
    "        input_masks = input_masks.repeat_interleave(J, dim=0)\n",
    "        for k in range(max_len):\n",
    "            w = self.dropout(w)\n",
    "            _, hidden = self.gru(w, hidden)  # 1,B,D\n",
    "\n",
    "            # B,T,D * B,D,1 => B,T\n",
    "            attn_e = torch.bmm(encoder_output, hidden.permute(1, 2, 0))  # B,T,1\n",
    "#             attn_e = attn_e.squeeze(-1).masked_fill(input_masks, -1e9)\n",
    "            attn_e = attn_e.squeeze(-1).masked_fill(input_masks, -1e4)\n",
    "            attn_history = F.softmax(attn_e, -1)  # B,T\n",
    "\n",
    "            if self.proj_layer:\n",
    "                hidden_proj = torch.matmul(hidden, self.proj_layer.weight)\n",
    "            else:\n",
    "                hidden_proj = hidden\n",
    "\n",
    "            # B,D * D,V => B,V\n",
    "            attn_v = torch.matmul(\n",
    "                hidden_proj.squeeze(0), self.embed.weight.transpose(0, 1)\n",
    "            )  # B,V\n",
    "            attn_vocab = F.softmax(attn_v, -1)\n",
    "\n",
    "            # B,1,T * B,T,D => B,1,D\n",
    "            context = torch.bmm(attn_history.unsqueeze(1), encoder_output)  # B,1,D\n",
    "            p_gen = self.sigmoid(\n",
    "                self.w_gen(torch.cat([w, hidden.transpose(0, 1), context], -1))\n",
    "            )  # B,1\n",
    "            p_gen = p_gen.squeeze(-1)\n",
    "\n",
    "            p_context_ptr = torch.zeros_like(attn_vocab).to(input_ids.device)\n",
    "            p_context_ptr.scatter_add_(1, input_ids, attn_history)  # copy B,V\n",
    "            p_final = p_gen * attn_vocab + (1 - p_gen) * p_context_ptr  # B,V\n",
    "            _, w_idx = p_final.max(-1)\n",
    "\n",
    "            if teacher is not None:\n",
    "                w = self.embedding(teacher[:, :, k]).transpose(0, 1).reshape(batch_size * J, 1, -1)\n",
    "            else:\n",
    "                w = self.embedding(w_idx).unsqueeze(1)  # B,1,D\n",
    "            if k == 0:\n",
    "                gated_logit = self.w_gate(context.squeeze(1))  # B,3\n",
    "                all_gate_outputs = gated_logit.view(batch_size, J, self.n_gate)\n",
    "            all_point_outputs[:, :, k, :] = p_final.view(batch_size, J, self.vocab_size)\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56421870",
   "metadata": {
    "id": "56421870"
   },
   "source": [
    "## 모델 및 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26f2936",
   "metadata": {
    "id": "d26f2936",
    "outputId": "f8d96419-d1ba-4bf3-a923-3eb77b3b031f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is initialized\n"
     ]
    }
   ],
   "source": [
    "slot_vocab = []\n",
    "for slot in slot_meta:\n",
    "    slot_vocab.append(\n",
    "        tokenizer.encode(slot.replace('-', ' '),\n",
    "                         add_special_tokens=False)\n",
    "    )\n",
    "    \n",
    "config = BertConfig.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "config.model_name_or_path = 'dsksd/bert-ko-small-minimal'\n",
    "# config.n_gate = len(processor.gating2id)\n",
    "config.n_gate = cfg.n_gate\n",
    "config.proj_dim = None\n",
    "\n",
    "model = TRADE(config, slot_vocab, slot_meta)\n",
    "\n",
    "model.to(device)\n",
    "print(\"Model is initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb6d5e2",
   "metadata": {
    "id": "cbb6d5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train: 46170\n",
      "# dev: 5075\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, \n",
    "                          batch_size=16, \n",
    "                          sampler=train_sampler, \n",
    "                          collate_fn=processor.collate_fn,\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True,\n",
    "                          )\n",
    "\n",
    "print(\"# train:\", len(train_data))\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, \n",
    "                        batch_size=8, \n",
    "                        sampler=dev_sampler, \n",
    "                        collate_fn=processor.collate_fn,\n",
    "                        num_workers=4,\n",
    "                        pin_memory=True,\n",
    "                        )\n",
    "\n",
    "print(\"# dev:\", len(dev_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b706c4e",
   "metadata": {
    "id": "2b706c4e"
   },
   "source": [
    "## Optimizer & Scheduler 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8593e4b",
   "metadata": {
    "id": "d8593e4b"
   },
   "outputs": [],
   "source": [
    "n_epochs = cfg.num_train_epochs\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.01,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=cfg.learning_rate, eps=cfg.adam_epsilon)\n",
    "warmup_steps = int(t_total * cfg.warmup_ratio)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    ")\n",
    "teacher_forcing = cfg.teacher_forcing_ratio\n",
    "# model.to(device)\n",
    "\n",
    "def masked_cross_entropy_for_value(logits, target, pad_idx=0):\n",
    "    mask = target.ne(pad_idx)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    log_probs_flat = torch.log(logits_flat)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / (mask.sum().float())\n",
    "    return loss\n",
    "\n",
    "loss_fnc_1 = masked_cross_entropy_for_value  # generation\n",
    "loss_fnc_2 = nn.CrossEntropyLoss()  # gating\n",
    "loss_fnc_pretrain = nn.CrossEntropyLoss()  # MLM pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a4edf96-508a-4c79-83be-733979663f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장될 파일 위치 생성\n",
    "if not os.path.exists(f\"{cfg.model_dir}/{wandb.run.name}\"):\n",
    "#     os.mkdir(f\"{cfg.model_dir}\")\n",
    "    os.mkdir(f\"{cfg.model_dir}/{wandb.run.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3399d04-2bce-4967-a251-d8b292bebdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(\n",
    "    vars(cfg),\n",
    "    open(f\"{cfg.model_dir}/{wandb.run.name}/exp_config.json\", \"w\"),\n",
    "    indent=2,\n",
    "    ensure_ascii=False,\n",
    ")\n",
    "json.dump(\n",
    "    slot_meta,\n",
    "    open(f\"{cfg.model_dir}/slot_meta.json\", \"w\"),\n",
    "    indent=2,\n",
    "    ensure_ascii=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb73492",
   "metadata": {
    "id": "0fb73492"
   },
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aaf8687",
   "metadata": {
    "id": "8aaf8687",
    "outputId": "85617036-0949-469a-ea4a-d8abc9fdcf12",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLM_PRE = True\n",
    "\n",
    "scaler = GradScaler()\n",
    "n_pretrain_epochs = 3\n",
    "\n",
    "def mlm_pretrain(loader, n_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(loader)):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "        \n",
    "        with autocast(): # 밑에 해당하는 코드를 자동으로 mixed precision으로 변환시켜서 실행\n",
    "            logits, labels = model.forward_pretrain(input_ids, tokenizer)\n",
    "            loss = loss_fnc_pretrain(logits.view(-1, config.vocab_size), labels.view(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(loader), loss.item()))\n",
    "\n",
    "if MLM_PRE:\n",
    "    for epoch in range(n_pretrain_epochs):\n",
    "        mlm_pretrain(train_loader, n_pretrain_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f9d8dd",
   "metadata": {
    "id": "58f9d8dd"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d004571d-d0c3-4236-9e2e-847d283d5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'scheduler.state_dict': scheduler.state_dict(),\n",
    "#         },'tmp.model.bin')\n",
    "\n",
    "ckpt = torch.load('tmp.model.bin')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.to(device)\n",
    "optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "# scheduler.load_state_dict(ckpt['scheduler.state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23538cd2",
   "metadata": {
    "id": "23538cd2",
    "outputId": "9456c9d1-d30e-419e-ed85-86ddd5854911",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2886 [00:01<51:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [0/2886] loss: 0.0385856069624424 gen: 0.03522958606481552 gate: 0.003356022061780095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 101/2886 [01:01<29:13,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [100/2886] loss: 0.04682090878486633 gen: 0.031805574893951416 gate: 0.015015332959592342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 201/2886 [02:01<27:03,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [200/2886] loss: 0.04550093784928322 gen: 0.04474420100450516 gate: 0.0007567384163849056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 301/2886 [03:00<24:57,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [300/2886] loss: 0.02762472629547119 gen: 0.027412667870521545 gate: 0.00021205896337050945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 401/2886 [03:58<21:47,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [400/2886] loss: 0.01613502763211727 gen: 0.01571708917617798 gate: 0.00041793924174271524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 501/2886 [04:57<24:30,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [500/2886] loss: 0.030067481100559235 gen: 0.02944207191467285 gate: 0.0006254087202250957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 601/2886 [05:55<23:51,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [600/2886] loss: 0.030410708859562874 gen: 0.02914070338010788 gate: 0.001270006294362247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 701/2886 [06:54<22:15,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [700/2886] loss: 0.05332624539732933 gen: 0.05118023231625557 gate: 0.00214601238258183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 801/2886 [07:54<18:26,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [800/2886] loss: 0.025891892611980438 gen: 0.024980438873171806 gate: 0.0009114528656937182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 901/2886 [08:53<17:36,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [900/2886] loss: 0.01877494528889656 gen: 0.018709994852542877 gate: 6.495110574178398e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1001/2886 [09:52<18:16,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1000/2886] loss: 0.030525047332048416 gen: 0.030432933941483498 gate: 9.211351425619796e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1101/2886 [10:50<17:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1100/2886] loss: 0.016968248412013054 gen: 0.013309621252119541 gate: 0.0036586278583854437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1201/2886 [11:49<15:53,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1200/2886] loss: 0.0171981081366539 gen: 0.017080456018447876 gate: 0.00011765128874685615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1301/2886 [12:47<14:36,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1300/2886] loss: 0.02037067897617817 gen: 0.02032819204032421 gate: 4.2487768951104954e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 1401/2886 [13:46<14:47,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1400/2886] loss: 0.032428160309791565 gen: 0.032327800989151 gate: 0.00010035950981546193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1501/2886 [14:45<12:54,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1500/2886] loss: 0.025729717686772346 gen: 0.025449499487876892 gate: 0.00028021863545291126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1601/2886 [15:43<13:25,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1600/2886] loss: 0.015783799812197685 gen: 0.015704961493611336 gate: 7.883746729930863e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1701/2886 [16:41<12:24,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1700/2886] loss: 0.028908835723996162 gen: 0.02851296029984951 gate: 0.0003958755114581436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1801/2886 [17:40<10:38,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1800/2886] loss: 0.03069692850112915 gen: 0.030636005103588104 gate: 6.092256444389932e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1901/2886 [18:39<10:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [1900/2886] loss: 0.013830875046551228 gen: 0.01379421167075634 gate: 3.66633539670147e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2001/2886 [19:37<08:21,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2000/2886] loss: 0.016865618526935577 gen: 0.016823071986436844 gate: 4.254604209563695e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2101/2886 [20:35<07:39,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2100/2886] loss: 0.019694289192557335 gen: 0.01956585794687271 gate: 0.00012843142030760646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 2201/2886 [21:36<06:44,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2200/2886] loss: 0.02744816616177559 gen: 0.027282744646072388 gate: 0.0001654222869547084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 2301/2886 [22:34<05:17,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2300/2886] loss: 0.02487608790397644 gen: 0.024702219292521477 gate: 0.00017386891704518348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 2401/2886 [23:33<04:45,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2400/2886] loss: 0.02906790003180504 gen: 0.02841595932841301 gate: 0.000651939888484776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2501/2886 [24:31<03:42,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2500/2886] loss: 0.01771087944507599 gen: 0.01763898693025112 gate: 7.189202005974948e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 2601/2886 [25:32<02:38,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2600/2886] loss: 0.03462297096848488 gen: 0.034576211124658585 gate: 4.6761597332078964e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 2701/2886 [26:30<01:53,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2700/2886] loss: 0.030892521142959595 gen: 0.012497988529503345 gate: 0.018394531682133675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 2801/2886 [27:28<00:49,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [2800/2886] loss: 0.030797092244029045 gen: 0.026598118245601654 gate: 0.004198973998427391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2886/2886 [28:18<00:00,  1.70it/s]\n",
      "100%|██████████| 635/635 [02:00<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.6108374384236454, 'turn_slot_accuracy': 0.9870695128626251, 'turn_slot_f1': 0.9413211894206762}\n",
      "'--Update Best checkpoint!, epoch: 1'\n",
      "--Saving best model checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "  0%|          | 1/2886 [00:01<49:38,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [0/2886] loss: 0.045541439205408096 gen: 0.02865423820912838 gate: 0.016887200996279716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 101/2886 [01:01<27:42,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [100/2886] loss: 0.021033475175499916 gen: 0.01873994991183281 gate: 0.002293525729328394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 201/2886 [02:00<25:06,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [200/2886] loss: 0.011448057368397713 gen: 0.009432303719222546 gate: 0.0020157531835138798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 301/2886 [03:00<24:57,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [300/2886] loss: 0.027593042701482773 gen: 0.02735261060297489 gate: 0.0002404312981525436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 401/2886 [03:58<23:09,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [400/2886] loss: 0.04968748241662979 gen: 0.02602601796388626 gate: 0.02366146445274353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 501/2886 [04:56<20:54,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [500/2886] loss: 0.045130111277103424 gen: 0.043976079672575 gate: 0.001154032303020358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 601/2886 [05:55<23:24,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [600/2886] loss: 0.041153766214847565 gen: 0.02801438421010971 gate: 0.013139383867383003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 701/2886 [06:53<22:16,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [700/2886] loss: 0.010424511507153511 gen: 0.010145289823412895 gate: 0.0002792217128444463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 801/2886 [07:52<21:21,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [800/2886] loss: 0.018742863088846207 gen: 0.016397370025515556 gate: 0.0023454935289919376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 901/2886 [08:50<19:52,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [900/2886] loss: 0.04873919486999512 gen: 0.03398391976952553 gate: 0.014755276963114738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1001/2886 [09:49<19:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1000/2886] loss: 0.05258360877633095 gen: 0.04790079966187477 gate: 0.004682808183133602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1101/2886 [10:47<17:59,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1100/2886] loss: 0.026704492047429085 gen: 0.025701720267534256 gate: 0.0010027713142335415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1201/2886 [11:45<15:05,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1200/2886] loss: 0.03163466230034828 gen: 0.030045390129089355 gate: 0.0015892722876742482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1301/2886 [12:45<15:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1300/2886] loss: 0.04021570459008217 gen: 0.03553926199674606 gate: 0.00467644352465868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 1401/2886 [13:44<14:35,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1400/2886] loss: 0.01624140702188015 gen: 0.01584966853260994 gate: 0.0003917384019587189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1501/2886 [14:43<13:42,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1500/2886] loss: 0.016415314748883247 gen: 0.014272852800786495 gate: 0.0021424617152661085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1601/2886 [15:42<12:27,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1600/2886] loss: 0.05150020122528076 gen: 0.044073570519685745 gate: 0.0074266307055950165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1701/2886 [16:42<12:42,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1700/2886] loss: 0.053172096610069275 gen: 0.03451456502079964 gate: 0.018657531589269638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1801/2886 [17:40<10:45,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1800/2886] loss: 0.05333475396037102 gen: 0.03993688523769379 gate: 0.013397869653999805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1901/2886 [18:39<08:32,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] [1900/2886] loss: 0.04136032983660698 gen: 0.0401897169649601 gate: 0.001170613570138812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1939/2886 [19:02<09:18,  1.70it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.05 GiB (GPU 0; 31.72 GiB total capacity; 24.97 GiB already allocated; 693.56 MiB free; 29.83 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7026ef177aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.05 GiB (GPU 0; 31.72 GiB total capacity; 24.97 GiB already allocated; 693.56 MiB free; 29.83 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "MLM_DURING = False\n",
    "\n",
    "# backward pass시 gradient 정보가 손실되지 않게 하려고 사용(loss에 scale factor를 곱해서 gradient 값이 너무 작아지는 것을 방지)\n",
    "scaler = GradScaler()\n",
    "best_score, best_checkpoint = 0, 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_loss = []\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_loader)):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [\n",
    "            b.to(device) if not isinstance(b, list) else b for b in batch\n",
    "        ]\n",
    "        # mask\n",
    "        if cfg.mask:\n",
    "            change_mask_prop = 0.8\n",
    "            mask_p = random.random()\n",
    "            if cfg.mask and mask_p < change_mask_prop:\n",
    "                input_ids = custom_to_mask(input_ids)\n",
    "        # teacher forcing\n",
    "        if teacher_forcing > 0.0 and random.random() < teacher_forcing:\n",
    "            tf = target_ids\n",
    "        else:\n",
    "            tf = None\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():  # 밑에 해당하는 코드를 자동으로 mixed precision으로 변환시켜서 실행\n",
    "            all_point_outputs, all_gate_outputs = model(input_ids, segment_ids, input_masks, target_ids.size(-1))  # gt - length (generation)\n",
    "            # generation loss\n",
    "            loss_1 = loss_fnc_1(all_point_outputs.contiguous(), target_ids.contiguous().view(-1))\n",
    "            # gating loss\n",
    "            loss_2 = loss_fnc_2(all_gate_outputs.contiguous().view(-1, 5), gating_ids.contiguous().view(-1))\n",
    "            loss = loss_1 + loss_2\n",
    "        \n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "        # global_step 추가 부분\n",
    "        wandb.log({\"train/learning_rate\": get_lr(scheduler),\n",
    "                   \"train/epoch\": epoch\n",
    "                   })\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                 f\"[{epoch}/{n_epochs}] [{step}/{len(train_loader)}] loss: {loss.item()} gen: {loss_1.item()} gate: {loss_2.item()}\"\n",
    "            )\n",
    "            wandb.log({\n",
    "                \"train/loss\": loss.item(),\n",
    "                \"train/gen_loss\": loss_1.item(),\n",
    "                \"train/gate_loss\": loss_2.item(),\n",
    "            })\n",
    "            \n",
    "    if MLM_DURING:\n",
    "        mlm_pretrain(train_loader, n_epochs)\n",
    "                \n",
    "    predictions = inference(model, dev_loader, processor, device, cfg.n_gate)\n",
    "    eval_result, batch_miss_labels = _evaluation(predictions, dev_labels, slot_meta)\n",
    "    \n",
    "#     # -- eval 단계에서 Loss, Accuracy 로그 저장\n",
    "#     wandb.log({\n",
    "#         \"eval/join_goal_acc\": eval_result[\"joint_goal_accuracy\"],\n",
    "#         \"eval/turn_slot_f1\": eval_result[\"turn_slot_f1\"],\n",
    "#         \"eval/turn_slot_acc\": eval_result[\"turn_slot_accuracy\"],\n",
    "#     })\n",
    "    \n",
    "#     for k, v in eval_result.items():\n",
    "#         print(f\"{k}: {v}\")\n",
    "        \n",
    "    if best_score < eval_result['joint_goal_accuracy']:\n",
    "        cpprint(f\"--Update Best checkpoint!, epoch: {epoch+1}\")\n",
    "        best_score = eval_result['joint_goal_accuracy']\n",
    "        best_checkpoint = epoch\n",
    "        if not os.path.isdir(cfg.model_dir):\n",
    "            os.makedirs(cfg.model_dir)\n",
    "        print(\"--Saving best model checkpoint\")\n",
    "        torch.save(model.state_dict(), f\"{cfg.model_dir}/{wandb.run.name}/best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler.state_dict': scheduler.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'gen_loss': loss_1.item(),\n",
    "            'gate_loss': loss_2.item(),\n",
    "        }, os.path.join(f\"{cfg.model_dir}/{wandb.run.name}\", \"training_best_checkpoint.bin\"))\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{cfg.model_dir}/{wandb.run.name}/last.pth\")\n",
    "#     print(f\"time for 1 epoch: {time.time() - start_time}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48021e08",
   "metadata": {
    "id": "48021e08"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02cb1fb",
   "metadata": {
    "id": "b02cb1fb",
    "outputId": "1a99a246-b8f1-4365-b51b-774dff71091c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 36946.73it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef9937",
   "metadata": {
    "id": "b2ef9937",
    "outputId": "6a6da7b0-2754-4b23-cf43-f5906932e0fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 944/944 [01:45<00:00,  8.92it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7163b",
   "metadata": {
    "id": "03a7163b"
   },
   "outputs": [],
   "source": [
    "json.dump(predictions, open('predictions.csv', 'w'), indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TAPT_solution.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
