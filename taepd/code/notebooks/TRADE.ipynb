{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "d2pFWE8yslWe",
    "outputId": "f75065ef-f0e1-4442-c452-fd765e0e86b8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, BertConfig, AdamW, get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from data_utils import (\n",
    "    load_dataset, \n",
    "    get_examples_from_dialogues, \n",
    "    convert_state_dict, \n",
    "    DSTInputExample, \n",
    "    OpenVocabDSTFeature, \n",
    "    DSTPreprocessor, \n",
    "    WOSDataset)\n",
    "    \n",
    "from inference import inference\n",
    "from evaluation import _evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# !wandb login  # run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU        \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_output_dir(output_path, exist_ok=False):\n",
    "  path = Path(output_path)\n",
    "  if (path.exists() and exist_ok) or (not path.exists()):\n",
    "    return str(path)\n",
    "  else:\n",
    "    dirs = glob.glob(f\"{path}*\")\n",
    "    matches = [re.search(rf\"%s(\\d+)\" %path.stem, d) for d in dirs]\n",
    "    i = [int(m.groups()[0]) for m in matches if m]\n",
    "    n = max(i) + 1 if i else 2\n",
    "    return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### args setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'data_dir': 'data/train_dataset',\n",
    "    'model_dir': 'trade',\n",
    "    'train_batch_size': 16,\n",
    "    'eval_batch_size': 32,\n",
    "    'learning_rate': 1e-4,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'max_grad_norm': 1.0,   \n",
    "    'num_train_epochs': 30,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'random_seed': 42,\n",
    "    'model_name_or_path': 'monologg/koelectra-base-v3-discriminator',\n",
    "    'hidden_size': 768,\n",
    "    'vocab_size': None,\n",
    "    'hidden_dropout_prob': 0.1,\n",
    "    'proj_dim': None,\n",
    "    'teacher_forcing_ratio': 0.5,    \n",
    "}\n",
    "\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:33tldxmx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1532, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 1668, in _on_finish\n",
      "    self.history._flush()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_history.py\", line 59, in _flush\n",
      "    self._callback(row=self._data, step=self._step)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 836, in _history_callback\n",
      "    row, step, publish_step=not_using_tensorboard\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 227, in publish_history\n",
      "    self._publish_history(history)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 211, in _publish_history\n",
      "    self._publish(rec)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 528, in _publish\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:33tldxmx). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">atomic-eon-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/taepd/TRADE\" target=\"_blank\">https://wandb.ai/taepd/TRADE</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/taepd/TRADE/runs/1nims2tx\" target=\"_blank\">https://wandb.ai/taepd/TRADE/runs/1nims2tx</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/repo/taepd/code/notebooks/wandb/run-20210510_110457-1nims2tx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb sweep 생성 시 parameters에 전달하는 config 설정\n",
    "# hyperparameter_defaults = dict(\n",
    "#     batch_size = args.batch_size,\n",
    "#     learning_rate = args.learning_rate,\n",
    "#     epochs = args.num_train_epochs,\n",
    "#     weight_decay = args.weight_decay,\n",
    "#     attn_head = args.attn_head,\n",
    "#     distance_metric = args.distance_metric,\n",
    "    \n",
    "#     dropout = 0.1,\n",
    "#     smoothing = 0.2\n",
    "#     model_name = 'BertForSequenceClassification',\n",
    "#     tokenizer_name = 'BertTokenizer',\n",
    "#     )\n",
    "\n",
    "# wandb.init(config=hyperparameter_defaults, project=\"TRADE\")\n",
    "wandb.init(project=\"TRADE\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pEFUfQPslWm"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WS9rj3p8slWn",
    "outputId": "cb0b1943-8b38-4376-a73e-03568667e116",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 8814.25it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 2805.83it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_file = \"/opt/ml/repo/taepd/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/repo/taepd/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)\n",
    "\n",
    "# dialogue_level=False : SUMBT와 다르게 dialogue context level로 input하므로\n",
    "train_examples = get_examples_from_dialogues(train_data,\n",
    "                                             user_first=False,\n",
    "                                             dialogue_level=False)\n",
    "dev_examples = get_examples_from_dialogues(dev_data,\n",
    "                                           user_first=False,\n",
    "                                           dialogue_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nvz2dyx0slWo",
    "outputId": "0bd5b9e6-2e51-4f80-af48-7fb68216137e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46170\n",
      "5075\n"
     ]
    }
   ],
   "source": [
    "print(len(train_examples))\n",
    "print(len(dev_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJLQi71XslWp"
   },
   "source": [
    "## TRADE Preprocessor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUkp1LQislWp"
   },
   "source": [
    "기존의 GRU 기반의 인코더를 BERT-based Encoder로 바꿀 준비를 합시다.\n",
    "\n",
    "1. 현재 `_convert_example_to_feature`에서는 `max_seq_length`를 핸들하고 있지 않습니다. `input_id`와 `segment_id`가 `max_seq_length`를 넘어가면 좌측부터 truncate시키는 코드를 삽입하세요.\n",
    "\n",
    "2. hybrid approach에서 얻은 교훈을 바탕으로 gate class를 3개에서 5개로 늘려봅시다.\n",
    "    - WoS 데이터셋의 특성상 (boolean type이 많음) 'yes', 'no' gate를 추가했을 때 더 나은 성능을 보입니다.\n",
    "    - `gating2id`를 수정하세요\n",
    "    - 이에 따른 `recover_state`를 수정하세요.\n",
    "\n",
    "3. word dropout을 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "id": "zSrtvakXslWq",
    "outputId": "f2fcce63-1026-464e-e6ba-a7397f112415",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TRADEPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=512,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology\n",
    "        self.gating2id =  {\"none\": 0, \"dontcare\": 1, \"yes\": 2, \"no\": 3, \"ptr\": 4}         \n",
    "        self.id2gating = {v: k for k, v in self.gating2id.items()}\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def _convert_example_to_feature(self, example):\n",
    "        dialogue_context = \" [SEP] \".join(example.context_turns + example.current_turn)\n",
    "\n",
    "        input_id = self.src_tokenizer.encode(dialogue_context, add_special_tokens=False)\n",
    "        max_length = self.max_seq_length - 2\n",
    "        \n",
    "        if len(input_id) > max_length:\n",
    "            gap = len(input_id) - max_length\n",
    "            input_id = input_id[gap:]\n",
    "       \n",
    "        input_id = (\n",
    "            [self.src_tokenizer.cls_token_id]\n",
    "            + input_id\n",
    "            + [self.src_tokenizer.sep_token_id]\n",
    "        )\n",
    "        segment_id = [0] * len(input_id)  # bert기반이 되었을 땐 segment 구분이 필요할 수 있음\n",
    "\n",
    "        target_ids = []\n",
    "        gating_id = []\n",
    "        if not example.label:\n",
    "            example.label = []\n",
    "\n",
    "        state = convert_state_dict(example.label)\n",
    "        for slot in self.slot_meta:\n",
    "            value = state.get(slot, \"none\")\n",
    "            target_id = self.trg_tokenizer.encode(value, add_special_tokens=False) + [\n",
    "                self.trg_tokenizer.sep_token_id\n",
    "            ]  # [sep]를 추가하여, AutoRegressive시, EOS token으로 사용\n",
    "            target_ids.append(target_id)\n",
    "            gating_id.append(self.gating2id.get(value, self.gating2id[\"ptr\"]))\n",
    "        target_ids = self.pad_ids(target_ids, self.trg_tokenizer.pad_token_id)   # collate_fn에서 처리해주는 것 같은데?\n",
    "        return OpenVocabDSTFeature(\n",
    "            example.guid, input_id, segment_id, gating_id, target_ids\n",
    "        )\n",
    "\n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "    def recover_state(self, gate_list, gen_list):\n",
    "        assert len(gate_list) == len(self.slot_meta)\n",
    "        assert len(gen_list) == len(self.slot_meta)\n",
    "\n",
    "        recovered = []\n",
    "        for slot, gate, value in zip(self.slot_meta, gate_list, gen_list):\n",
    "            if self.id2gating[gate] == \"none\":\n",
    "                continue\n",
    "\n",
    "            if self.id2gating[gate] == \"dontcare\":\n",
    "                recovered.append(\"%s-%s\" % (slot, \"dontcare\"))\n",
    "                continue\n",
    "\n",
    "            token_id_list = []\n",
    "            for id_ in value:\n",
    "                if id_ in self.trg_tokenizer.all_special_ids:\n",
    "                    break\n",
    "\n",
    "                token_id_list.append(id_)\n",
    "            value = self.trg_tokenizer.decode(token_id_list, skip_special_tokens=True)\n",
    "\n",
    "            if value == \"none\":\n",
    "                continue\n",
    "\n",
    "            recovered.append(\"%s-%s\" % (slot, value))\n",
    "\n",
    "        return recovered\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor(\n",
    "            self.pad_ids([b.input_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "        )\n",
    "        segment_ids = torch.LongTensor(\n",
    "            self.pad_ids([b.segment_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "        )\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "\n",
    "        gating_ids = torch.LongTensor([b.gating_id for b in batch])\n",
    "        target_ids = self.pad_id_of_matrix(\n",
    "            [torch.LongTensor(b.target_ids) for b in batch],\n",
    "            self.trg_tokenizer.pad_token_id,\n",
    "        )\n",
    "        return input_ids, segment_ids, input_masks, gating_ids, target_ids, guids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I69eYMJyslWr"
   },
   "source": [
    "## Convert_Examples_to_Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QBNpq0UQslWs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512)\n",
    "\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)\n",
    "\n",
    "# 간이 테스트 시 사용\n",
    "# train_features = processor.convert_examples_to_features(train_examples[:1000])\n",
    "# dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "56Qzk1zBslWs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46170\n",
      "5075\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUgtNxRDslWs"
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piIwZkF4slWt"
   },
   "source": [
    "1. `GRUEncoder`를 `BertModel`로 교체하세요. 이에 따라 `tie_weight` 함수가 수정되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g5ChWcG3slWt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TRADE(nn.Module):\n",
    "    def __init__(self, config, slot_vocab, slot_meta, pad_idx=0):\n",
    "        super(TRADE, self).__init__()\n",
    "        self.slot_meta = slot_meta\n",
    "        # https://huggingface.co/dsksd/bert-ko-small-minimal/blob/main/config.json\n",
    "        if config.model_name_or_path:\n",
    "            self.encoder = BertModel.from_pretrained(config.model_name_or_path)\n",
    "        else:\n",
    "            self.encoder = BertModel(config)    \n",
    "          \n",
    "        self.decoder = SlotGenerator(\n",
    "            config.vocab_size,\n",
    "            config.hidden_size,\n",
    "            config.hidden_dropout_prob,\n",
    "            config.n_gate,\n",
    "            None,\n",
    "            pad_idx,\n",
    "        )\n",
    "        \n",
    "        # init for only subword embedding\n",
    "        self.decoder.set_slot_idx(slot_vocab)\n",
    "        self.tie_weight()\n",
    "\n",
    "    # encoder와 decoder의 embedding matrix sharing    \n",
    "    def tie_weight(self):\n",
    "#         self.decoder.embed = self.encoder.get_input_embeddings()\n",
    "        self.decoder.embed.weight = self.encoder.embeddings.word_embeddings.weight\n",
    "        if self.decoder.proj_layer:\n",
    "            self.decoder.proj_layer.weight = self.encoder.proj_layer.weight\n",
    "\n",
    "    def forward(self, \n",
    "                input_ids,  # p^history를 vocal size로 변환하기 위해 input_ids받음 \n",
    "                token_type_ids,\n",
    "                attention_mask=None, \n",
    "                max_len=10,  # maximum length를 target_id에서 받고, inference 때는 고정된 constant를 받음\n",
    "                teacher=None):  # teacher forcing을 위한 GT Sequence\n",
    "\n",
    "        encoder_outputs, pooled_output = self.encoder(input_ids=input_ids)\n",
    "        all_point_outputs, all_gate_outputs = self.decoder(\n",
    "            input_ids, encoder_outputs, pooled_output.unsqueeze(0), attention_mask, max_len, teacher\n",
    "        )\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs\n",
    "    \n",
    "class SlotGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, hidden_size, dropout, n_gate, proj_dim=None, pad_idx=0\n",
    "    ):\n",
    "        super(SlotGenerator, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = nn.Embedding(\n",
    "            vocab_size, hidden_size, padding_idx=pad_idx\n",
    "        )  # shared with encoder\n",
    "\n",
    "        if proj_dim:\n",
    "            self.proj_layer = nn.Linear(hidden_size, proj_dim, bias=False)\n",
    "        else:\n",
    "            self.proj_layer = None\n",
    "        self.hidden_size = proj_dim if proj_dim else hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            self.hidden_size, self.hidden_size, 1, dropout=dropout, batch_first=True\n",
    "        )  # unidirectional GRU\n",
    "        self.n_gate = n_gate\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_gen = nn.Linear(self.hidden_size * 3, 1)  # p_gen을 만들 때 3가지를 concat하므로 *3\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.w_gate = nn.Linear(self.hidden_size, n_gate)\n",
    "\n",
    "    def set_slot_idx(self, slot_vocab_idx):\n",
    "        whole = []\n",
    "        max_length = max(map(len, slot_vocab_idx))   # tokenized slot_meta 길이 최댓값: ex)4\n",
    "        for idx in slot_vocab_idx:\n",
    "            if len(idx) < max_length:\n",
    "                gap = max_length - len(idx)\n",
    "                idx.extend([self.pad_idx] * gap)\n",
    "            whole.append(idx)\n",
    "        self.slot_embed_idx = whole  # torch.LongTensor(whole)  ex) [[6728, 6479, 1, 1],..]\n",
    "\n",
    "    def embedding(self, x):\n",
    "        x = self.embed(x)\n",
    "        if self.proj_layer:\n",
    "            x = self.proj_layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, encoder_output, hidden, input_masks, max_len, teacher=None\n",
    "    ):\n",
    "        input_masks = input_masks.ne(1)\n",
    "        # J, slot_meta : key : [domain, slot] ex> LongTensor([1,2])\n",
    "        # J,2\n",
    "        batch_size = encoder_output.size(0)\n",
    "        slot = torch.LongTensor(self.slot_embed_idx).to(input_ids.device)  ##\n",
    "        slot_e = torch.sum(self.embedding(slot), 1)  # J,d  J * slot_vocab_idx 를 embedding을 거쳐서 sum해주어 J * hidden 이 됨\n",
    "        J = slot_e.size(0)\n",
    "\n",
    "        all_point_outputs = torch.zeros(batch_size, J, max_len, self.vocab_size).to(  # max_len: max gen len\n",
    "            input_ids.device\n",
    "        )  # Output Tensor (for Placeholder)\n",
    "        \n",
    "        # Parallel Decoding\n",
    "        w = slot_e.repeat(batch_size, 1).unsqueeze(1)\n",
    "        hidden = hidden.repeat_interleave(J, dim=1)\n",
    "        encoder_output = encoder_output.repeat_interleave(J, dim=0)\n",
    "        input_ids = input_ids.repeat_interleave(J, dim=0)\n",
    "        input_masks = input_masks.repeat_interleave(J, dim=0)\n",
    "        for k in range(max_len):\n",
    "            w = self.dropout(w)\n",
    "            _, hidden = self.gru(w, hidden)  # 1,B,D\n",
    "\n",
    "            # B,T,D * B,D,1 => B,T,1  (T가 |X_t|인듯, input sequence length)\n",
    "            attn_e = torch.bmm(encoder_output, hidden.permute(1, 2, 0))  # B,T,1\n",
    "            attn_e = attn_e.squeeze(-1).masked_fill(input_masks, -1e9)\n",
    "            attn_history = F.softmax(attn_e, -1)  # B,T\n",
    "\n",
    "            if self.proj_layer:\n",
    "                hidden_proj = torch.matmul(hidden, self.proj_layer.weight)\n",
    "            else:\n",
    "                hidden_proj = hidden\n",
    "\n",
    "            # B,D * D,V => B,V\n",
    "            attn_v = torch.matmul(\n",
    "                hidden_proj.squeeze(0), self.embed.weight.transpose(0, 1)\n",
    "            )  # B,V\n",
    "            attn_vocab = F.softmax(attn_v, -1)\n",
    "\n",
    "            # B,1,T * B,T,D => B,1,D\n",
    "            context = torch.bmm(attn_history.unsqueeze(1), encoder_output)  # B,1,D\n",
    "            p_gen = self.sigmoid(\n",
    "                self.w_gen(torch.cat([w, hidden.transpose(0, 1), context], -1))\n",
    "            )  # B,1\n",
    "            p_gen = p_gen.squeeze(-1)\n",
    "\n",
    "            p_context_ptr = torch.zeros_like(attn_vocab).to(input_ids.device)\n",
    "            p_context_ptr.scatter_add_(1, input_ids, attn_history)  # copy B,V\n",
    "            p_final = p_gen * attn_vocab + (1 - p_gen) * p_context_ptr  # B,V\n",
    "            _, w_idx = p_final.max(-1)\n",
    "\n",
    "            if teacher is not None:\n",
    "#                 w = self.embedding(teacher[:, :, k]).transpose(0, 1).reshape(batch_size * J, 1, -1)\n",
    "                w = self.embedding(teacher[:, :, k]).reshape(batch_size * J, 1, -1)\n",
    "            else:\n",
    "                w = self.embedding(w_idx).unsqueeze(1)  # B,1,D\n",
    "            if k == 0:\n",
    "                gated_logit = self.w_gate(context.squeeze(1))  # B,3\n",
    "                all_gate_outputs = gated_logit.view(batch_size, J, self.n_gate)\n",
    "            all_point_outputs[:, :, k, :] = p_final.view(batch_size, J, self.vocab_size)\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuMGMbwsslWu"
   },
   "source": [
    "# 모델 및 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "r3E5k__7slWu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f7113c75090>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_vocab = []\n",
    "for slot in slot_meta:\n",
    "    slot_vocab.append(\n",
    "        tokenizer.encode(slot.replace('-', ' '),  # 원래는 domain, slot을 영어와 달리 동일 길이로 토큰화되지 않기에 그냥 concat\n",
    "                         add_special_tokens=False)\n",
    "    )\n",
    "    \n",
    "config = BertConfig.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "config.model_name_or_path = 'dsksd/bert-ko-small-minimal'\n",
    "config.n_gate = len(processor.gating2id)\n",
    "config.proj_dim = None\n",
    "model = TRADE(config, slot_vocab, slot_meta)\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "mDynT9SlslWv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=4, sampler=train_sampler, collate_fn=processor.collate_fn,  num_workers=4)\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, batch_size=8, sampler=dev_sampler, collate_fn=processor.collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sme-Sir0slWv"
   },
   "source": [
    "# Optimizer & Scheduler 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oQW7VbbdslWv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.01,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps=0.1, num_training_steps=t_total\n",
    "# )\n",
    "\n",
    "\n",
    "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0.1, num_training_steps=t_total, num_cycles=20\n",
    ")\n",
    "teacher_forcing = 0.5\n",
    "model.to(device)\n",
    "\n",
    "def masked_cross_entropy_for_value(logits, target, pad_idx=0):  # logits: (B, J, k, V)\n",
    "    mask = target.ne(pad_idx)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))   # B*J*k, V (ex) [900, 35000])\n",
    "    log_probs_flat = torch.log(logits_flat)\n",
    "    target_flat = target.view(-1, 1)  # 열벡터로 변환  [900, 1]\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)  # [900, 1]\n",
    "    losses = losses_flat.view(*target.size())   # 행벡터로 변환 [900]\n",
    "    losses = losses * mask.float()   # mask(padding)은 제외\n",
    "    loss = losses.sum() / (mask.sum().float())\n",
    "    return loss\n",
    "\n",
    "loss_fnc_1 = masked_cross_entropy_for_value  # generation\n",
    "loss_fnc_2 = nn.CrossEntropyLoss()  # gating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpB8ri1jslWw"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtCFrehRslWw",
    "outputId": "eaa2101f-2d4d-427c-8266-f8604a8ed307",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/11543 [00:00<1:35:06,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [0/11543] 0.000571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 102/11543 [00:19<34:37,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [100/11543] 0.002938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 202/11543 [00:35<29:23,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [200/11543] 0.000046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 302/11543 [00:52<30:32,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [300/11543] 0.001168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 402/11543 [01:10<32:54,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [400/11543] 0.004316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 502/11543 [01:27<29:22,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [500/11543] 0.000267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 602/11543 [01:43<30:47,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [600/11543] 0.000268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 702/11543 [02:00<31:52,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [700/11543] 0.000828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 802/11543 [02:17<29:49,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [800/11543] 0.007376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 902/11543 [02:35<28:20,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [900/11543] 0.042318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 1002/11543 [02:52<25:43,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1000/11543] 0.000236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1102/11543 [03:08<30:06,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1100/11543] 0.001753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1201/11543 [03:25<28:07,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1200/11543] 0.000596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 1302/11543 [03:43<30:20,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1300/11543] 0.000104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1402/11543 [04:01<30:25,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1400/11543] 0.000186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1502/11543 [04:18<25:21,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1500/11543] 0.000577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1602/11543 [04:35<24:35,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1600/11543] 0.000299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1701/11543 [04:52<30:08,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1700/11543] 0.002795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1802/11543 [05:09<28:34,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1800/11543] 0.000266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1902/11543 [05:26<27:19,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [1900/11543] 0.000254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2001/11543 [05:42<28:12,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2000/11543] 0.000629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2102/11543 [06:01<22:25,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2100/11543] 0.000212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 2202/11543 [06:18<27:40,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2200/11543] 0.000256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 2302/11543 [06:35<24:33,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2300/11543] 0.001375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2402/11543 [06:53<25:59,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2400/11543] 0.000264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2502/11543 [07:10<23:25,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2500/11543] 0.000116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2601/11543 [07:26<23:17,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2600/11543] 0.000573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2702/11543 [07:44<27:34,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2700/11543] 0.002634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2802/11543 [08:02<25:48,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2800/11543] 0.002770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2902/11543 [08:19<25:30,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [2900/11543] 0.000272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 3002/11543 [08:37<24:32,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3000/11543] 0.002927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3102/11543 [08:54<22:42,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3100/11543] 0.042399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 3202/11543 [09:11<21:32,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3200/11543] 0.000056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 3302/11543 [09:29<22:23,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3300/11543] 0.005099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 3402/11543 [09:46<22:26,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3400/11543] 0.030062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3502/11543 [10:03<26:17,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3500/11543] 0.000632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3602/11543 [10:20<21:46,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3600/11543] 0.026330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3702/11543 [10:38<22:51,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3700/11543] 0.003287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3802/11543 [10:54<22:01,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3800/11543] 0.022889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3901/11543 [11:12<23:52,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [3900/11543] 0.000238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 4002/11543 [11:30<21:53,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4000/11543] 0.000411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 4102/11543 [11:47<21:59,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4100/11543] 0.001264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4202/11543 [12:04<22:18,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4200/11543] 0.000075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 4301/11543 [12:21<20:32,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4300/11543] 0.021467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 4402/11543 [12:38<19:05,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4400/11543] 0.001129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 4502/11543 [12:55<16:29,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4500/11543] 0.000138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 4601/11543 [13:13<22:28,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4600/11543] 0.018837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4702/11543 [13:30<22:10,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4700/11543] 0.000693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4802/11543 [13:47<22:09,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4800/11543] 0.000613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4902/11543 [14:04<20:34,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [4900/11543] 0.000156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 5001/11543 [14:21<17:19,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5000/11543] 0.000045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 5101/11543 [14:38<18:44,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5100/11543] 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5202/11543 [14:55<18:17,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5200/11543] 0.001163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 5301/11543 [15:12<14:56,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5300/11543] 0.000124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 5402/11543 [15:29<17:47,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5400/11543] 0.001305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 5502/11543 [15:46<18:24,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5500/11543] 0.001716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 5602/11543 [16:04<17:16,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5600/11543] 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 5701/11543 [16:21<17:34,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5700/11543] 0.001008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5801/11543 [16:38<15:57,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5800/11543] 0.000572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5902/11543 [16:56<15:23,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [5900/11543] 0.000466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 6002/11543 [17:14<17:34,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [6000/11543] 0.004014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 6102/11543 [17:30<16:19,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] [6100/11543] 0.000153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 6115/11543 [17:33<16:18,  5.55it/s]"
     ]
    }
   ],
   "source": [
    "# for checkpoint management\n",
    "chk_list = []\n",
    "output_dir = increment_output_dir(wandb.run.name)\n",
    "PATIENCE = 0 \n",
    "if not os.path.exists(f\"checkpoint/{output_dir}\"):\n",
    "    os.makedirs(f\"checkpoint/{output_dir}\")  \n",
    "\n",
    "best_score, best_checkpoint = 0, 0\n",
    "epoch_miss_labels = defaultdict(list)\n",
    "for epoch in range(n_epochs):\n",
    "    batch_loss = []\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_loader)):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids,_ = [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "        if teacher_forcing > 0.0 and random.random() < teacher_forcing:\n",
    "            tf = target_ids\n",
    "        else:\n",
    "            tf = None\n",
    "\n",
    "        all_point_outputs, all_gate_outputs = model(input_ids, segment_ids, input_masks, target_ids.size(-1))  # gt - length (generation)\n",
    "        loss_1 = loss_fnc_1(all_point_outputs.contiguous(), target_ids.contiguous().view(-1))\n",
    "        loss_2 = loss_fnc_2(all_gate_outputs.contiguous().view(-1, 5), gating_ids.contiguous().view(-1))\n",
    "        loss = loss_1 + loss_2\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % 100 == 0:                   \n",
    "            print('[%d/%d] [%d/%d] %f' % (epoch+1, n_epochs, step, len(train_loader), loss.item()))\n",
    "            # -- train 단계에서 Loss, Accuracy 로그 저장\n",
    "            wandb.log({\n",
    "                \"train/loss\": loss.item(),\n",
    "                \"train/gen_loss\": loss_1.item(),\n",
    "                \"train/gate_loss\": loss_2.item(),\n",
    "                \"train/epoch\": epoch+1\n",
    "            })\n",
    "            \n",
    "    predictions = inference(model, dev_loader, processor, device)\n",
    "#     eval_result,  = _evaluation(predictions, dev_labels, slot_meta)\n",
    "    eval_result, batch_miss_labels = _evaluation(predictions, dev_labels, slot_meta)\n",
    "            \n",
    "    epoch_miss_labels[epoch].extend(batch_miss_labels)   \n",
    "    \n",
    "    wandb.log({\n",
    "            \"eval/loss\": loss.item(),\n",
    "            \"Joint Goal Accuracy\": eval_result['joint_goal_accuracy'],\n",
    "            \"Turn Slot_Accuracy\": eval_result['turn_slot_accuracy'],\n",
    "            \"Turn Slot F1\": eval_result['turn_slot_f1']\n",
    "            })\n",
    "      \n",
    "    for k, v in eval_result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    if best_score < eval_result['joint_goal_accuracy']:\n",
    "        print(\"Update Best checkpoint!\")\n",
    "        best_score = eval_result['joint_goal_accuracy']\n",
    "        best_checkpoint = epoch\n",
    "        if not os.path.isdir('./checkpoint'):\n",
    "            os.makedirs('./checkpoint')\n",
    "        output_path = f\"checkpoint/{output_dir}/{epoch}_{step}_{best_score}.pth\"\n",
    "        chk_list.append(output_path)\n",
    "\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, output_path)\n",
    "        PATIENCE = 0\n",
    "    else:\n",
    "        PATIENCE += 1\n",
    "        if PATIENCE == 1:\n",
    "            break\n",
    "\n",
    "#     torch.save(model.state_dict(), f\"{args.model_dir}/model-{epoch}.bin\")\n",
    "#     torch.save(model.state_dict(), f\"checkpoint/trage/{output_dir}/model-{epoch}.bin\")\n",
    "# print(f\"Best checkpoint: {args.model_dir}/model-{best_checkpoint}.bin\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnqoseXQslWx"
   },
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "IS3dPV9qslWx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 16252.49it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/repo/taepd/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WTadcC6GslWx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1847/1847 [05:46<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "aqTUAT2cslWy"
   },
   "outputs": [],
   "source": [
    "json.dump(predictions, open('predictions.csv', 'w'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eda용 missing label exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('miss_labels.json', 'w') as outfile:\n",
    "    json.dump(epoch_miss_labels, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config = BertConfig.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "# config.model_name_or_path = 'dsksd/bert-ko-small-minimal'\n",
    "# config.n_gate = len(processor.gating2id)\n",
    "# config.proj_dim = None\n",
    "# model1 = TRADE(config, slot_vocab, slot_meta)\n",
    "# PATH = 'checkpoint/golden-forest-14/3_11542_0.7749753694581281.pth'\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model1.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1847/1847 [05:27<00:00,  5.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(predictions, open('predictions.csv', 'w'), indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TRADE.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
