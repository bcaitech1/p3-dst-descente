{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e75f7a-efa4-4f8f-ae2b-9f146df29ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install prettyprinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5480165-e5e6-40b2-be60-06ca8e46e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3863f74a-cbc9-48f2-ac06-e8a61d6ea7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, AutoTokenizer, AutoConfig\n",
    "\n",
    "from data_utils import (YamlConfigManager, WOSDataset, get_examples_from_dialogues, load_dataset, extract_label,\n",
    "                        set_seed, custom_to_mask, custom_get_examples_from_dialogues, custom_load_dataset)\n",
    "\n",
    "from evaluation import _evaluation\n",
    "from inference import inference\n",
    "from model import TRADE, masked_cross_entropy_for_value\n",
    "from preprocessor import TRADEPreprocessor\n",
    "from prettyprinter import cpprint\n",
    "\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea76b50d-a9c5-47cd-b2e7-95c3cc7e670e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70e2376-5bc5-403e-8a7f-186098cc0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easydict.EasyDict({\n",
      "    'data_dir': '../input',\n",
      "    'model_dir': 'results',\n",
      "    'train_batch_size': 4,\n",
      "    'eval_batch_size': 8,\n",
      "    'learning_rate': 1e-05,\n",
      "    'adam_epsilon': 1e-08,\n",
      "    'max_grad_norm': 1.0,\n",
      "    'num_train_epochs': 30,\n",
      "    'warmup_ratio': 0.0,\n",
      "    'random_seed': 42,\n",
      "    'n_gate': 5,\n",
      "    'teacher_forcing_ratio': 0.5,\n",
      "    'model_name_or_path': 'klue/roberta-large',\n",
      "    'proj_dim': 'None',\n",
      "    'tag': ['trade'],\n",
      "    'use_kfold': False,\n",
      "    'num_k': 0,\n",
      "    'val_ratio': 0.1,\n",
      "    'scheduler': 'Linear',\n",
      "    'mask': False\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "cfg = YamlConfigManager('./config.yml', 'base').values\n",
    "cpprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ac08d8-410a-4892-b1c5-f511005bc770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current learning rate\n",
    "def get_lr(scheduler):\n",
    "    return scheduler.get_last_lr()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebb526d-d6f0-4a16-bdfa-600edb5fb019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:00<00:00, 8552.51it/s] \n",
      "100%|██████████| 1000/1000 [00:00<00:00, 13331.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# random seed 고정\n",
    "set_seed(cfg.random_seed)\n",
    "\n",
    "# Data Loading\n",
    "# train_data_file = f\"{cfg.data_dir}/wos-v1_train.json\"\n",
    "train_data = json.load(open(f\"{cfg.data_dir}/wos-v1_train.json\"))\n",
    "dev_data = json.load(open(f\"{cfg.data_dir}/wos-v1_dev.json\"))\n",
    "dev_labels = extract_label(dev_data)\n",
    "slot_meta = json.load(open(f\"{cfg.data_dir}/slot_meta.json\"))\n",
    "\n",
    "# train_data, dev_data, dev_labels = load_dataset(train_data_file, cfg.val_ratio)\n",
    "# train_data, dev_data, dev_labels = custom_load_dataset(train_data_file, cfg.val_ratio, k=0)\n",
    "\n",
    "train_examples = custom_get_examples_from_dialogues(\n",
    "    train_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "dev_examples = custom_get_examples_from_dialogues(\n",
    "    dev_data, user_first=False, dialogue_level=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c99340d3-9a2c-4fa9-9061-915f61dd5743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSTInputExample(guid='wos-v1_train_00000-0', context_turns=[], current_turn=['', ' # ', '서울 중앙에 있는 박물관을 찾아주세요', ' * '], label=['관광-종류-박물관', '관광-지역-서울 중앙'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07631841-706c-4b78-933f-5d32bde5fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta\n"
     ]
    }
   ],
   "source": [
    "# Define Preprocessor\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name_or_path)\n",
    "\n",
    "# Dealing with long texts The maximum sequence length of BERT is 512.\n",
    "if 'roberta' in cfg.model_name_or_path:\n",
    "    processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=510, n_gate=cfg.n_gate)  # roberta 특성상 510까지만 가능  https://github.com/pytorch/fairseq/issues/1177\n",
    "    print('roberta')\n",
    "else:\n",
    "    processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512, n_gate=cfg.n_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69681250-741e-467b-9179-b799e53f5a10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Extracting Features...'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-70bfd342b9a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extracting Featrues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting Features...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_custom_convert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdev_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_custom_convert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DST/TRADE_descente/preprocessor.py\u001b[0m in \u001b[0;36msep_custom_convert_examples_to_features\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msep_custom_convert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sep_custom_convert_example_to_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecover_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DST/TRADE_descente/preprocessor.py\u001b[0m in \u001b[0;36m_sep_custom_convert_example_to_feature\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mcontext_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mcurrent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mcontext_segment_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m                 ``convert_tokens_to_ids`` method).\n\u001b[1;32m   2058\u001b[0m         \"\"\"\n\u001b[0;32m-> 2059\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2060\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2376\u001b[0m         )\n\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2379\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mbatched_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         batched_output = self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mbatched_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    383\u001b[0m         )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extracting Featrues\n",
    "cpprint('Extracting Features...')\n",
    "train_features = processor.sep_custom_convert_examples_to_features(train_examples)\n",
    "dev_features = processor.sep_custom_convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60162a83-bd1c-4fe1-8270-406f11549317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 전체 train data InputFeatur 저장\n",
    "# with open('custom_train_features', 'wb') as f:\n",
    "#     pickle.dump(train_features, f)\n",
    "# with open('custom_dev_features', 'wb') as f:\n",
    "#     pickle.dump(dev_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211b7774-b447-4d87-973d-2ecd124b4d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'custom_train_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3c5060584a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 저장된 파일 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'custom_train_features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'custom_dev_features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdev_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'custom_train_features'"
     ]
    }
   ],
   "source": [
    "# 저장된 파일 사용\n",
    "with open('custom_train_features', 'rb') as f:\n",
    "    train_features = pickle.load(f)\n",
    "with open('custom_dev_features', 'rb') as f:\n",
    "    dev_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ac70ca-510c-40a5-b2bd-845a246ba6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slot Meta tokenizing for the decoder initial inputs\n",
    "tokenized_slot_meta = []\n",
    "for slot in slot_meta:\n",
    "    tokenized_slot_meta.append(\n",
    "        tokenizer.encode(slot.replace(\"-\", \" \"), add_special_tokens=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec392330-ac93-499b-9d20-15370366ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is initialized\n"
     ]
    }
   ],
   "source": [
    "# Model 선언\n",
    "config = AutoConfig.from_pretrained(cfg.model_name_or_path)\n",
    "config.model_name_or_path = cfg.model_name_or_path\n",
    "config.n_gate = cfg.n_gate\n",
    "config.proj_dim = None\n",
    "\n",
    "model = TRADE(config, tokenized_slot_meta)\n",
    "\n",
    "model.to(device)\n",
    "print(\"Model is initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126758aa-9a0e-4eff-9a95-b1f35ca00a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --wandb initialize with configuration\n",
    "wandb.init(project='KLUE-DST', tags=cfg.tag, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e51a0d-f3d2-4a71-8e58-37dbafbb4130",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-79b67bf55ec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWOSDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_loader = DataLoader(\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=cfg.train_batch_size,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    "    num_workers=4,  # num_worker = 4 * num_GPU\n",
    "    pin_memory=True,\n",
    ")\n",
    "print(\"# train:\", len(train_data))\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(\n",
    "    dev_data,\n",
    "    batch_size=cfg.eval_batch_size,\n",
    "    sampler=dev_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "print(\"# dev:\", len(dev_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32a5559-d31a-4937-8825-997da97673ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6c186aa52f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer_grouped_parameters = [\n\u001b[1;32m      6\u001b[0m     {\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;34m\"params\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mno_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;34m\"weight_decay\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     },\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimizer 및 Scheduler 선언\n",
    "n_epochs = cfg.num_train_epochs\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=cfg.learning_rate, eps=cfg.adam_epsilon)\n",
    "warmup_steps = int(t_total * cfg.warmup_ratio)\n",
    "# learning rate decreases linearly from the initial lr set in the optimizer to 0\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    ")\n",
    "teacher_forcing = cfg.teacher_forcing_ratio\n",
    "\n",
    "loss_fnc_1 = masked_cross_entropy_for_value  # generation\n",
    "loss_fnc_2 = nn.CrossEntropyLoss()  # gating\n",
    "loss_fnc_pretrain = nn.CrossEntropyLoss()  # MLM pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bdb7b28-a37c-49f3-ad41-8c949ab5ea9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6d5cdbf8f0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{cfg.model_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{cfg.model_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{cfg.model_dir}/{wandb.run.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{cfg.model_dir}/{wandb.run.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# 모델 저장될 파일 위치 생성\n",
    "if not os.path.exists(f\"{cfg.model_dir}\"):\n",
    "    os.mkdir(f\"{cfg.model_dir}\")\n",
    "if not os.path.exists(f\"{cfg.model_dir}/{wandb.run.name}\"):\n",
    "    os.mkdir(f\"{cfg.model_dir}/{wandb.run.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ef705d3-5aa4-44a8-a169-34f2c7afcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(\n",
    "    vars(cfg),\n",
    "    open(f\"{cfg.model_dir}/{wandb.run.name}/exp_config.json\", \"w\"),\n",
    "    indent=2,\n",
    "    ensure_ascii=False,\n",
    ")\n",
    "json.dump(\n",
    "    slot_meta,\n",
    "    open(f\"{cfg.model_dir}/slot_meta.json\", \"w\"),\n",
    "    indent=2,\n",
    "    ensure_ascii=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910b61e-bcfe-45ae-a050-94d300be0ea0",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a7cff0-4c9d-429b-8547-1b3ff44fca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_data = json.load(open(f\"../input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "# eval_examples = get_examples_from_dialogues(\n",
    "#     eval_data, user_first=False, dialogue_level=False\n",
    "# )\n",
    "\n",
    "# # Extracting Featrues\n",
    "# eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "# eval_data = WOSDataset(eval_features)\n",
    "# eval_sampler = SequentialSampler(eval_data)\n",
    "# eval_loader = DataLoader(\n",
    "#     eval_data,\n",
    "#     batch_size=8,\n",
    "#     sampler=eval_sampler,\n",
    "#     collate_fn=processor.collate_fn,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48019bdd-182f-44ab-987c-52074b8f4af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MLM_PRE = True\n",
    "\n",
    "# scaler = GradScaler()\n",
    "# n_pretrain_epochs = 10\n",
    "\n",
    "# def mlm_pretrain(loader, n_epochs):\n",
    "#     model.train()\n",
    "#     for step, batch in enumerate(tqdm(loader)):\n",
    "#         input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "        \n",
    "#         with autocast(): # 밑에 해당하는 코드를 자동으로 mixed precision으로 변환시켜서 실행\n",
    "#             logits, labels = model.forward_pretrain(input_ids, tokenizer)\n",
    "#             loss = loss_fnc_pretrain(logits.view(-1, config.vocab_size), labels.view(-1))\n",
    "\n",
    "#         scaler.scale(loss).backward()\n",
    "#         nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "#         scheduler.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         if step % 100 == 0:\n",
    "#             print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(loader), loss.item()))\n",
    "\n",
    "# if MLM_PRE:\n",
    "#     for epoch in range(n_pretrain_epochs):\n",
    "#         mlm_pretrain(eval_loader, n_pretrain_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeda079-8a8c-4d60-93bc-bc84d376c6f3",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0db76-2c8d-4e4d-98cc-33b2f29be7a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] [0/14698] loss: 10.327384948730469 gen: 8.79484748840332 gate: 1.5325372219085693\n",
      "[0/30] [100/14698] loss: 7.341711044311523 gen: 6.595045566558838 gate: 0.746665358543396\n",
      "[0/30] [200/14698] loss: 5.657776355743408 gen: 4.9181108474731445 gate: 0.7396653294563293\n",
      "[0/30] [300/14698] loss: 4.197666168212891 gen: 3.5040550231933594 gate: 0.6936109066009521\n",
      "[0/30] [400/14698] loss: 3.966791868209839 gen: 3.1811580657958984 gate: 0.7856337428092957\n",
      "[0/30] [500/14698] loss: 2.7266788482666016 gen: 2.219189405441284 gate: 0.5074893236160278\n",
      "[0/30] [600/14698] loss: 3.014867067337036 gen: 2.3325817584991455 gate: 0.6822852492332458\n",
      "[0/30] [700/14698] loss: 2.2547967433929443 gen: 1.696719765663147 gate: 0.5580769777297974\n",
      "[0/30] [800/14698] loss: 2.1247658729553223 gen: 1.6216602325439453 gate: 0.5031057000160217\n",
      "[0/30] [900/14698] loss: 1.988816261291504 gen: 1.441561222076416 gate: 0.5472550392150879\n",
      "[0/30] [1000/14698] loss: 2.1181466579437256 gen: 1.5566035509109497 gate: 0.5615431666374207\n",
      "[0/30] [1100/14698] loss: 1.2709158658981323 gen: 0.8606894016265869 gate: 0.410226434469223\n",
      "[0/30] [1200/14698] loss: 1.8608064651489258 gen: 1.2694425582885742 gate: 0.5913638472557068\n",
      "[0/30] [1300/14698] loss: 2.1241321563720703 gen: 1.4696075916290283 gate: 0.6545245051383972\n",
      "[0/30] [1400/14698] loss: 1.2439024448394775 gen: 0.8699525594711304 gate: 0.37394994497299194\n",
      "[0/30] [1500/14698] loss: 1.3079986572265625 gen: 0.8839443325996399 gate: 0.4240543842315674\n",
      "[0/30] [1600/14698] loss: 1.041846752166748 gen: 0.6682606339454651 gate: 0.3735860586166382\n",
      "[0/30] [1700/14698] loss: 1.1397241353988647 gen: 0.7812748551368713 gate: 0.358449250459671\n",
      "[0/30] [1800/14698] loss: 1.7129690647125244 gen: 1.1076074838638306 gate: 0.6053615808486938\n",
      "[0/30] [1900/14698] loss: 1.4123376607894897 gen: 0.8913663029670715 gate: 0.5209713578224182\n",
      "[0/30] [2000/14698] loss: 1.844970703125 gen: 1.1803834438323975 gate: 0.6645872592926025\n",
      "[0/30] [2100/14698] loss: 1.0696895122528076 gen: 0.6816920638084412 gate: 0.38799744844436646\n",
      "[0/30] [2200/14698] loss: 1.1642298698425293 gen: 0.684747040271759 gate: 0.47948282957077026\n",
      "[0/30] [2300/14698] loss: 0.9384729266166687 gen: 0.6044057011604309 gate: 0.3340672254562378\n",
      "[0/30] [2400/14698] loss: 1.6163572072982788 gen: 1.0862339735031128 gate: 0.530123233795166\n",
      "[0/30] [2500/14698] loss: 1.2338615655899048 gen: 0.7522533535957336 gate: 0.48160821199417114\n",
      "[0/30] [2600/14698] loss: 1.1601479053497314 gen: 0.7439537048339844 gate: 0.4161941409111023\n",
      "[0/30] [2700/14698] loss: 1.3649412393569946 gen: 0.8436479568481445 gate: 0.5212932825088501\n",
      "[0/30] [2800/14698] loss: 0.9289454221725464 gen: 0.5850706696510315 gate: 0.3438747525215149\n",
      "[0/30] [2900/14698] loss: 1.6862854957580566 gen: 1.104486346244812 gate: 0.5817990899085999\n",
      "[0/30] [3000/14698] loss: 1.209991216659546 gen: 0.7299510836601257 gate: 0.48004013299942017\n",
      "[0/30] [3100/14698] loss: 1.4086806774139404 gen: 0.8862673044204712 gate: 0.522413432598114\n",
      "[0/30] [3200/14698] loss: 0.8092515468597412 gen: 0.5362394452095032 gate: 0.27301210165023804\n",
      "[0/30] [3300/14698] loss: 1.3351755142211914 gen: 0.9305513501167297 gate: 0.40462422370910645\n",
      "[0/30] [3400/14698] loss: 1.7831605672836304 gen: 1.0953985452651978 gate: 0.6877620220184326\n",
      "[0/30] [3500/14698] loss: 1.0128428936004639 gen: 0.626349925994873 gate: 0.38649290800094604\n",
      "[0/30] [3600/14698] loss: 1.108859896659851 gen: 0.7291555404663086 gate: 0.3797043561935425\n",
      "[0/30] [3700/14698] loss: 1.5510616302490234 gen: 1.1383930444717407 gate: 0.4126686155796051\n",
      "[0/30] [3800/14698] loss: 1.6575965881347656 gen: 1.1017961502075195 gate: 0.5558004379272461\n",
      "[0/30] [3900/14698] loss: 1.5256918668746948 gen: 1.066894769668579 gate: 0.4587971270084381\n",
      "[0/30] [4000/14698] loss: 0.9825223684310913 gen: 0.6182582974433899 gate: 0.36426404118537903\n",
      "[0/30] [4100/14698] loss: 1.028446078300476 gen: 0.6952258944511414 gate: 0.33322015404701233\n",
      "[0/30] [4200/14698] loss: 0.9938709139823914 gen: 0.616946816444397 gate: 0.3769240975379944\n",
      "[0/30] [4300/14698] loss: 1.3098039627075195 gen: 0.9160952568054199 gate: 0.3937087655067444\n",
      "[0/30] [4400/14698] loss: 0.9443174600601196 gen: 0.6510523557662964 gate: 0.29326507449150085\n",
      "[0/30] [4500/14698] loss: 1.0863184928894043 gen: 0.7750528454780579 gate: 0.3112656772136688\n",
      "[0/30] [4600/14698] loss: 1.1860706806182861 gen: 0.7927343845367432 gate: 0.39333632588386536\n",
      "[0/30] [4700/14698] loss: 1.2242662906646729 gen: 0.8378646373748779 gate: 0.3864016532897949\n",
      "[0/30] [4800/14698] loss: 1.1067373752593994 gen: 0.697017252445221 gate: 0.4097200930118561\n",
      "[0/30] [4900/14698] loss: 1.5635581016540527 gen: 1.083880066871643 gate: 0.4796780049800873\n",
      "[0/30] [5000/14698] loss: 1.08699631690979 gen: 0.7324150204658508 gate: 0.35458123683929443\n",
      "[0/30] [5100/14698] loss: 1.2308745384216309 gen: 0.8409730792045593 gate: 0.38990142941474915\n",
      "[0/30] [5200/14698] loss: 1.2617074251174927 gen: 0.8304488658905029 gate: 0.43125852942466736\n",
      "[0/30] [5300/14698] loss: 1.0100587606430054 gen: 0.7120093703269958 gate: 0.29804936051368713\n",
      "[0/30] [5400/14698] loss: 1.4101550579071045 gen: 0.8269524574279785 gate: 0.583202600479126\n",
      "[0/30] [5500/14698] loss: 1.444682002067566 gen: 1.0332539081573486 gate: 0.4114281237125397\n",
      "[0/30] [5600/14698] loss: 0.8370248079299927 gen: 0.5547423958778381 gate: 0.28228241205215454\n",
      "[0/30] [5700/14698] loss: 0.9202967882156372 gen: 0.5673204064369202 gate: 0.35297641158103943\n",
      "[0/30] [5800/14698] loss: 1.1351423263549805 gen: 0.7462451457977295 gate: 0.3888971507549286\n",
      "[0/30] [5900/14698] loss: 1.1786761283874512 gen: 0.8097889423370361 gate: 0.36888712644577026\n",
      "[0/30] [6000/14698] loss: 1.1986207962036133 gen: 0.7346444129943848 gate: 0.4639763832092285\n",
      "[0/30] [6100/14698] loss: 1.2275302410125732 gen: 0.8192423582077026 gate: 0.40828782320022583\n"
     ]
    }
   ],
   "source": [
    "# backward pass시 gradient 정보가 손실되지 않게 하려고 사용(loss에 scale factor를 곱해서 gradient 값이 너무 작아지는 것을 방지)\n",
    "scaler = GradScaler()\n",
    "best_score, best_checkpoint = 0, 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    batch_loss = []\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [\n",
    "            b.to(device) if not isinstance(b, list) else b for b in batch\n",
    "        ]\n",
    "        # mask\n",
    "        if cfg.mask:\n",
    "            change_mask_prop = 0.8\n",
    "            mask_p = random.random()\n",
    "            if cfg.mask and mask_p < change_mask_prop:\n",
    "                input_ids = custom_to_mask(input_ids)\n",
    "        # teacher forcing\n",
    "        if (\n",
    "            teacher_forcing > 0.0\n",
    "            and random.random() < teacher_forcing\n",
    "        ):\n",
    "            tf = target_ids\n",
    "        else:\n",
    "            tf = None\n",
    "\n",
    "        optimizer.zero_grad()  # optimizer는 input으로 model parameter를 가진다 -> zero_grad()로 파라미터 컨드롤 가능\n",
    "\n",
    "        with autocast():  # 밑에 해당하는 코드를 자동으로 mixed precision으로 변환시켜서 실행\n",
    "            all_point_outputs, all_gate_outputs = model(\n",
    "                input_ids, segment_ids, input_masks, target_ids.size(-1), tf\n",
    "            )\n",
    "            # generation loss\n",
    "            loss_1 = loss_fnc_1(\n",
    "                all_point_outputs.contiguous(),\n",
    "                target_ids.contiguous().view(-1),\n",
    "                tokenizer.pad_token_id,\n",
    "            )\n",
    "            \n",
    "            # gating loss\n",
    "            loss_2 = loss_fnc_2(\n",
    "                all_gate_outputs.contiguous().view(-1, cfg.n_gate),\n",
    "                gating_ids.contiguous().view(-1),\n",
    "            )\n",
    "            loss = loss_1 + loss_2\n",
    "        \n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        # global_step 추가 부분\n",
    "        wandb.log({\"train/learning_rate\": get_lr(scheduler),\n",
    "                   \"train/epoch\": epoch\n",
    "                   })\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                f\"[{epoch}/{n_epochs}] [{step}/{len(train_loader)}] loss: {loss.item()} gen: {loss_1.item()} gate: {loss_2.item()}\"\n",
    "            )\n",
    "\n",
    "            # -- train 단계에서 Loss, Accuracy 로그 저장\n",
    "            wandb.log({\n",
    "                \"train/loss\": loss.item(),\n",
    "                \"train/gen_loss\": loss_1.item(),\n",
    "                \"train/gate_loss\": loss_2.item(),\n",
    "            })\n",
    "\n",
    "#     predictions, p_logits, p_idx, g_logits = inference(model, dev_loader, processor, device, cfg.n_gate)\n",
    "    predictions = inference(model, dev_loader, processor, device, cfg.n_gate)\n",
    "    eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "\n",
    "    # -- eval 단계에서 Loss, Accuracy 로그 저장\n",
    "    wandb.log({\n",
    "        \"eval/join_goal_acc\": eval_result[\"joint_goal_accuracy\"],\n",
    "        \"eval/turn_slot_f1\": eval_result[\"turn_slot_f1\"],\n",
    "        \"eval/turn_slot_acc\": eval_result[\"turn_slot_accuracy\"],\n",
    "    })\n",
    "\n",
    "    for k, v in eval_result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    if best_score < eval_result['joint_goal_accuracy']:\n",
    "        cpprint(f\"--Update Best checkpoint!, epoch: {epoch+1}\")\n",
    "        best_score = eval_result['joint_goal_accuracy']\n",
    "        best_checkpoint = epoch\n",
    "        if not os.path.isdir(cfg.model_dir):\n",
    "            os.makedirs(cfg.model_dir)\n",
    "        print(\"--Saving best model checkpoint\")\n",
    "        torch.save(model.state_dict(), f\"{cfg.model_dir}/{wandb.run.name}/best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler.state_dict': scheduler.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'gen_loss': loss_1.item(),\n",
    "            'gate_loss': loss_2.item(),\n",
    "        }, os.path.join(f\"{cfg.model_dir}/{wandb.run.name}\", \"training_best_checkpoint.bin\"))\n",
    "        \n",
    "        # logit 저장\n",
    "#         np.save(os.path.join(f\"{cfg.model_dir}/{wandb.run.name}\", r'p_logits.npy'), p_logits)\n",
    "#         np.save(os.path.join(f\"{cfg.model_dir}/{wandb.run.name}\", r'p_idx.npy'), p_idx)\n",
    "#         np.save(os.path.join(f\"{cfg.model_dir}/{wandb.run.name}\", r'g_logits.npy'), g_logits)\n",
    "\n",
    "        \n",
    "    torch.save(model.state_dict(), f\"{cfg.model_dir}/{wandb.run.name}/last.pth\")\n",
    "    print(f\"time for 1 epoch: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397a9cb-5298-4f25-b6db-02877caa1d4d",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5426c2b-cef2-420c-b278-60c190f19515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3472.50it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data = json.load(open(f\"{cfg.data_dir}/wos-v1_dev_fixed_v2.json\"))\n",
    "eval_labels = extract_label(eval_data)\n",
    "\n",
    "eval_examples = custom_get_examples_from_dialogues(\n",
    "    eval_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.sep_custom_convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('results/TRADE_roberta-large/best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb164e7-ba8a-422f-a90d-f3684163bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 903/903 [02:53<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.7314507198228128, 'turn_slot_accuracy': 0.9913252122554636, 'turn_slot_f1': 0.9655316727871294}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = inference(model, eval_loader, processor, device, cfg.n_gate)\n",
    "eval_result = _evaluation(predictions, eval_labels, slot_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5c60a-f6fe-4760-b69b-819df395779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(predictions, open('predictions.csv', 'w'), indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
