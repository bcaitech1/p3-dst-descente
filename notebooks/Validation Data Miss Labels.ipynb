{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac3ed05-50b8-4c0d-abb8-1cad8e3dff9c",
   "metadata": {},
   "source": [
    "## Validation Data Miss Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63892bcc-344a-4c26-9d11-b51d0e8fa175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AdamW, get_linear_schedule_with_warmup\n",
    "from data_utils import (\n",
    "    load_dataset, \n",
    "    get_examples_from_dialogues, \n",
    "    convert_state_dict, \n",
    "    DSTInputExample, \n",
    "    OpenVocabDSTFeature, \n",
    "    DSTPreprocessor, \n",
    "    WOSDataset,\n",
    "    set_seed)\n",
    "\n",
    "from preprocessor import TRADEPreprocessor\n",
    "from model import TRADE\n",
    "from inference import inference\n",
    "from eval_ucompute_acc\n",
    "\n",
    "from prettyprinter import cpprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbce2d9-fda5-4806-bace-5c3a51d8f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b9ae22-2926-48f5-9c6b-6e877f5f5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01796276-bd6a-42b8-90af-21c6b61b3644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 8355.98it/s] \n",
      "100%|██████████| 699/699 [00:00<00:00, 15636.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_file = \"../input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"../input/data/train_dataset/slot_meta.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)\n",
    "\n",
    "train_examples = get_examples_from_dialogues(train_data,\n",
    "                                             user_first=False,\n",
    "                                             dialogue_level=False)\n",
    "dev_examples = get_examples_from_dialogues(dev_data,\n",
    "                                           user_first=False,\n",
    "                                           dialogue_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff571f1-72d3-4292-b945-b3a4b1bdbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54e18a3-ca1b-4548-930e-b296a6998be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Extracting Featrues\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(\n",
    "    dev_data,\n",
    "    batch_size=8,\n",
    "    sampler=dev_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba87fb99-ee01-4900-a30a-e3eef1525159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slot Meta tokenizing for the decoder initial inputs\n",
    "tokenized_slot_meta = []\n",
    "for slot in slot_meta:\n",
    "    tokenized_slot_meta.append(\n",
    "        tokenizer.encode(slot.replace(\"-\", \" \"), add_special_tokens=False)\n",
    "    )\n",
    "\n",
    "# Model 선언\n",
    "config = AutoConfig.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "config.model_name_or_path = 'dsksd/bert-ko-small-minimal'\n",
    "config.n_gate = 5\n",
    "config.proj_dim = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "491f96e6-870f-4bbd-a250-39acdaddefd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRADE(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): SlotGenerator(\n",
       "    (embed): Embedding(35000, 768, padding_idx=0)\n",
       "    (gru): GRU(768, 768, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (w_gen): Linear(in_features=2304, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "    (w_gate): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TRADE(config, tokenized_slot_meta)\n",
    "ckpt = torch.load('./result/electric-spaceship-30-best-26.pth', map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea12fb2-21ca-4b18-b97e-bb3331014371",
   "metadata": {},
   "source": [
    "#### 수정한 부분\n",
    "- self.miss_labels = {} 추가\n",
    "- update_labels 함수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a6be48-0250-4f92-9471-c4cc8ce6c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_utils.py\n",
    "class DSTEvaluator:\n",
    "    def __init__(self, slot_meta):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.miss_labels = {}\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        self.joint_goal_hit = 0\n",
    "        self.all_hit = 0\n",
    "        self.slot_turn_acc = 0\n",
    "        self.slot_F1_pred = 0\n",
    "        self.slot_F1_count = 0\n",
    "        \n",
    "    def update_labels(self, guid, gold, pred):\n",
    "        pred_set = set(pred)\n",
    "        gold_set = set(gold)\n",
    "        if pred_set != gold_set:\n",
    "            unpred_labels = sorted(list(gold_set - pred_set))\n",
    "            wrong_preds = sorted(list(pred_set-gold_set))\n",
    "            self.miss_labels[guid] = {'unpred_labels':unpred_labels, 'wrong_preds':wrong_preds}\n",
    "        \n",
    "        \n",
    "    def update(self, gold, pred):\n",
    "        # 매 turn마다 호출되는 함수\n",
    "        # gold, pred: List of state (=slot-value)\n",
    "        self.all_hit += 1\n",
    "        if set(pred) == set(gold):\n",
    "            self.joint_goal_hit += 1\n",
    "\n",
    "        temp_acc = compute_acc(gold, pred, self.slot_meta)\n",
    "        self.slot_turn_acc += temp_acc\n",
    "\n",
    "        temp_f1, _, _, count = compute_prf(gold, pred)\n",
    "        self.slot_F1_pred += temp_f1\n",
    "        self.slot_F1_count += count\n",
    "\n",
    "    def compute(self):\n",
    "        turn_acc_score = self.slot_turn_acc / self.all_hit\n",
    "        slot_F1_score = self.slot_F1_pred / self.slot_F1_count\n",
    "        joint_goal_accuracy = self.joint_goal_hit / self.all_hit\n",
    "        eval_result = {\n",
    "            \"joint_goal_accuracy\": joint_goal_accuracy,\n",
    "            \"turn_slot_accuracy\": turn_acc_score,\n",
    "            \"turn_slot_f1\": slot_F1_score,\n",
    "        }\n",
    "        return eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ca991-f65d-41d4-87cf-5ac39eeb94f4",
   "metadata": {},
   "source": [
    "#### 수정한 부분\n",
    "- evaluator.update_labels(k, l, p) 추가\n",
    "- miss_labels = evaluator.miss_labels 추가\n",
    "- return result, miss_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0af3b17-83c0-4cd8-8681-504ec1701643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation.py\n",
    "def _evaluation(preds, labels, slot_meta): # predictions, dev_labels, slot_meta)\n",
    "    evaluator = DSTEvaluator(slot_meta)\n",
    "\n",
    "    evaluator.init()\n",
    "    assert len(preds) == len(labels)\n",
    "\n",
    "    # k: guid, l: [state, state, ...]\n",
    "    for k, l in labels.items():\n",
    "        p = preds.get(k)\n",
    "        if p is None: # predictions에 에측된 states가 None인 경우\n",
    "            raise Exception(f\"{k} is not in the predictions!\")\n",
    "        evaluator.update(l, p)\n",
    "        evaluator.update_labels(k, l, p)\n",
    "        \n",
    "    miss_labels = evaluator.miss_labels\n",
    "    result = evaluator.compute()\n",
    "    #print(result)\n",
    "    return result, miss_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b539ee-15af-4ed6-90a7-6770b2a58029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [02:06<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = inference(model, dev_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "931aaae9-ae43-460b-b239-07fce8a58ea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bb474b54dcd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmiss_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-0596ddc9073f>\u001b[0m in \u001b[0;36m_evaluation\u001b[0;34m(preds, labels, slot_meta)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# predictions에 에측된 states가 None인 경우\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{k} is not in the predictions!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0506c6a27731>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, gold, pred)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_goal_hit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtemp_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslot_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslot_turn_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_acc' is not defined"
     ]
    }
   ],
   "source": [
    "eval_result, miss_labels = _evaluation(predictions, dev_labels, slot_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d3a7b-df5a-4c16-9205-fd8f6d4440e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpprint(miss_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
